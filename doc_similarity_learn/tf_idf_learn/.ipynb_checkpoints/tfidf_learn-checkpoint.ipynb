{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple algorithm comparing documents using tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2\n"
     ]
    }
   ],
   "source": [
    "# raw_documents = [\"I'm taking the show on the road.\",\n",
    "#                  \"My socks are a force multiplier.\",\n",
    "#              \"I am the barber who cuts everyone's hair who doesn't cut their own.\",\n",
    "#              \"Legend has it that the mind is a mad monkey.\",\n",
    "#             \"I make my own fun.\"]\n",
    "raw_documents=[\"\"\"Long ago, when there was no written history, these islands were the home of millions of happy birds; \n",
    "the resort of a hundred times more millions of fishes, sea lions, and other creatures. Here lived innumerable \n",
    "creatures predestined from the creation of the world to lay up a store of wealth for the British farmer, and a \n",
    "store of quite another sort for an immaculate Republican government.\"\"\",\n",
    "              \"\"\"In ages which have no record these islands were the home of millions of happy birds, \n",
    "              the resort of a hundred times more millions of fishes, of sea lions, and other creatures whose names \n",
    "              are not so common; the marine residence, in fact, of innumerable creatures predestined from the \n",
    "              creation of the world to lay up a store of wealth for the British farmer, and a store of quite \n",
    "              another sort for an immaculate Republican government.\"\"\"]\n",
    "print(\"Number of documents:\",len(raw_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['long', 'ago', ',', 'when', 'there', 'was', 'no', 'written', 'history', ',', 'these', 'islands', 'were', 'the', 'home', 'of', 'millions', 'of', 'happy', 'birds', ';', 'the', 'resort', 'of', 'a', 'hundred', 'times', 'more', 'millions', 'of', 'fishes', ',', 'sea', 'lions', ',', 'and', 'other', 'creatures', '.', 'here', 'lived', 'innumerable', 'creatures', 'predestined', 'from', 'the', 'creation', 'of', 'the', 'world', 'to', 'lay', 'up', 'a', 'store', 'of', 'wealth', 'for', 'the', 'british', 'farmer', ',', 'and', 'a', 'store', 'of', 'quite', 'another', 'sort', 'for', 'an', 'immaculate', 'republican', 'government', '.'], ['in', 'ages', 'which', 'have', 'no', 'record', 'these', 'islands', 'were', 'the', 'home', 'of', 'millions', 'of', 'happy', 'birds', ',', 'the', 'resort', 'of', 'a', 'hundred', 'times', 'more', 'millions', 'of', 'fishes', ',', 'of', 'sea', 'lions', ',', 'and', 'other', 'creatures', 'whose', 'names', 'are', 'not', 'so', 'common', ';', 'the', 'marine', 'residence', ',', 'in', 'fact', ',', 'of', 'innumerable', 'creatures', 'predestined', 'from', 'the', 'creation', 'of', 'the', 'world', 'to', 'lay', 'up', 'a', 'store', 'of', 'wealth', 'for', 'the', 'british', 'farmer', ',', 'and', 'a', 'store', 'of', 'quite', 'another', 'sort', 'for', 'an', 'immaculate', 'republican', 'government', '.']]\n"
     ]
    }
   ],
   "source": [
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in raw_documents]\n",
    "print(gen_docs)\n",
    "\n",
    "def tokenize(raw_documents):\n",
    "    gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in raw_documents]\n",
    "    return gen_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "Number of words in dictionary: 67\n",
      "0 happy\n",
      "1 for\n",
      "2 history\n",
      "3 an\n",
      "4 these\n",
      "5 when\n",
      "6 to\n",
      "7 creatures\n",
      "8 birds\n",
      "9 hundred\n",
      "10 times\n",
      "11 store\n",
      "12 government\n",
      "13 were\n",
      "14 sea\n",
      "15 millions\n",
      "16 resort\n",
      "17 the\n",
      "18 world\n",
      "19 lived\n",
      "20 ,\n",
      "21 ago\n",
      "22 immaculate\n",
      "23 written\n",
      "24 other\n",
      "25 british\n",
      "26 more\n",
      "27 there\n",
      "28 sort\n",
      "29 fishes\n",
      "30 lay\n",
      "31 no\n",
      "32 home\n",
      "33 of\n",
      "34 predestined\n",
      "35 lions\n",
      "36 quite\n",
      "37 ;\n",
      "38 up\n",
      "39 here\n",
      "40 islands\n",
      "41 innumerable\n",
      "42 farmer\n",
      "43 a\n",
      "44 long\n",
      "45 creation\n",
      "46 wealth\n",
      "47 republican\n",
      "48 .\n",
      "49 and\n",
      "50 another\n",
      "51 was\n",
      "52 from\n",
      "53 not\n",
      "54 marine\n",
      "55 have\n",
      "56 record\n",
      "57 fact\n",
      "58 which\n",
      "59 so\n",
      "60 in\n",
      "61 ages\n",
      "62 names\n",
      "63 common\n",
      "64 are\n",
      "65 residence\n",
      "66 whose\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary[5])\n",
    "print(\"Number of words in dictionary:\",len(dictionary))\n",
    "for i in range(len(dictionary)):\n",
    "    print(i, dictionary[i])\n",
    "    \n",
    "def make_dict(gen_docs):\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 5), (18, 1), (19, 1), (20, 5), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 7), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 3), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 1), (52, 1)], [(0, 1), (1, 2), (3, 1), (4, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 6), (18, 1), (20, 6), (22, 1), (24, 1), (25, 1), (26, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 9), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (40, 1), (41, 1), (42, 1), (43, 3), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (50, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)\n",
    "\n",
    "def make_corpus(gen_docs):\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create a tf-idf model from the corpus. Note that num_nnz is the number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=2, num_nnz=111)\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)\n",
    "s = 0\n",
    "for i in corpus:\n",
    "    s += len(i)\n",
    "print(s)\n",
    "\n",
    "def make_tf_idf(corpus):\n",
    "    tf_idf = gensim.models.TfidfModel(corpus)\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will create a similarity measure object in tf-idf space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 2 documents in 0 shards (stored under /home/ristohinno/nn_learn/doc_similarity_learn/tf_idf_learn)\n",
      "<class 'gensim.similarities.docsim.Similarity'>\n"
     ]
    }
   ],
   "source": [
    "def generate_sims(corpus, dictionary):\n",
    "    sims = gensim.similarities.Similarity(os.getcwd(),tf_idf[corpus],num_features=len(dictionary))\n",
    "    return sims\n",
    "\n",
    "sims = gensim.similarities.Similarity(os.getcwd(),tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))\n",
    "print(sims)\n",
    "print(type(sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now create a query document and convert it to tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_comparison=\"\"\"\"In ages which have no record these islands were the home of millions of happy birds, \n",
    "the resort of a hundred times more millions of fishes, of sea lions, and other creatures whose names \n",
    "are not so common; the marine residence, in fact, of innumerable creatures predestined from the creation of \n",
    "the world to lay up a store of wealth for the British farmer, and a store of quite another sort for an immaculate \n",
    "Republican government\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_tfidf_sim(docs, doc_comparison):\n",
    "    #original docs\n",
    "    gen_docs=tokenize(docs)\n",
    "    dictionary=make_dict(gen_docs)\n",
    "    corpus=make_corpus(gen_docs)\n",
    "    tf_idf=make_tf_idf(corpus)\n",
    "    sims=generate_sims(corpus, dictionary)\n",
    "    \n",
    "    #query doc\n",
    "    query_doc = [w.lower() for w in word_tokenize(doc_comparison)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "    \n",
    "    return sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=calculate_tfidf_sim(raw_documents, doc_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.99999994], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'in', 'ages', 'which', 'have', 'no', 'record', 'these', 'islands', 'were', 'the', 'home', 'of', 'millions', 'of', 'happy', 'birds', ',', 'the', 'resort', 'of', 'a', 'hundred', 'times', 'more', 'millions', 'of', 'fishes', ',', 'of', 'sea', 'lions', ',', 'and', 'other', 'creatures', 'whose', 'names', 'are', 'not', 'so', 'common', ';', 'the', 'marine', 'residence', ',', 'in', 'fact', ',', 'of', 'innumerable', 'creatures', 'predestined', 'from', 'the', 'creation', 'of', 'the', 'world', 'to', 'lay', 'up', 'a', 'store', 'of', 'wealth', 'for', 'the', 'british', 'farmer', ',', 'and', 'a', 'store', 'of', 'quite', 'another', 'sort', 'for', 'an', 'immaculate', 'republican', 'government']\n",
      "[(1, 2), (2, 2), (3, 1), (4, 1), (5, 1), (7, 1), (8, 6), (10, 1), (11, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 2), (18, 1), (19, 1), (20, 1), (22, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (31, 1), (32, 1), (34, 1), (35, 3), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 9), (51, 1), (52, 6), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1)]\n",
      "[(53, 0.24253562503633297), (54, 0.24253562503633297), (55, 0.24253562503633297), (56, 0.24253562503633297), (57, 0.24253562503633297), (58, 0.24253562503633297), (59, 0.24253562503633297), (60, 0.24253562503633297), (61, 0.24253562503633297), (62, 0.24253562503633297), (63, 0.24253562503633297), (64, 0.24253562503633297), (65, 0.48507125007266594), (66, 0.24253562503633297)]\n"
     ]
    }
   ],
   "source": [
    "query_doc = [w.lower() for w in word_tokenize(doc_comparison)]\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We show an array of document similarities to query. We see that the second document is the most similar with the overlapping of socks and force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.99999994], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
