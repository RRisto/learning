{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b523e0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lesson 4: Building a Multi-Document Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a323703",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9625ab2-71b6-4fd0-904e-42df80d3215f",
   "metadata": {
    "height": 47,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import openai\n",
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3221a474-5817-4db2-af46-e029042a75a5",
   "metadata": {
    "height": 47,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8f3185-3221-4b00-bd38-41d36e4a3307",
   "metadata": {
    "height": 149,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils_rag import get_doc_tools\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff58c52",
   "metadata": {
    "height": 64,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a124a438-5609-402e-8642-69d1088cb9ad",
   "metadata": {
    "height": 166,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76aaa9c0-50f0-4930-bd14-98b9b0727675",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Set up logging for OpenAI\n",
    "openai.logging = logging.getLogger(\"openai\")\n",
    "openai.logging.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eede70c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Setup an agent over articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18771e69",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download 11 ICLR papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d01d2c-547f-4054-b0fe-ed9b1a9cc3b5",
   "metadata": {
    "height": 472,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
    "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
    "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
    "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
    "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
    "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
    "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"loftq.pdf\",\n",
    "    \"swebench.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "    \"zipformer.pdf\",\n",
    "    \"values.pdf\",\n",
    "    \"finetune_fair_diffusion.pdf\",\n",
    "    \"knowledge_card.pdf\",\n",
    "    \"metra.pdf\",\n",
    "    \"vr_mcl.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e650f6-3388-453e-b8c6-4036a9b3a098",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_files_recursively(directory):\n",
    "    paths=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "    return paths\n",
    "\n",
    "# Example usage\n",
    "papers=list_files_recursively('support_articles/')\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "455909f7-fafd-4267-96b8-77d04ef9bcd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for url, paper in zip(urls, papers):\n",
    "#      !wget \"{url}\" -O \"{paper}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77426cb",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To download these papers, below is the needed code:\n",
    "\n",
    "\n",
    "    #for url, paper in zip(urls, papers):\n",
    "         #!wget \"{url}\" -O \"{paper}\"\n",
    "    \n",
    "    \n",
    "**Note**: The pdf files are included with this lesson. To access these papers, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fcf030-2b05-42f6-b40b-e95d838ab435",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sanitize_names(name):\n",
    "    name=re.sub('[^0-9a-zA-Z]+', '_', name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5ee34d-02ac-4537-ae20-7ef6c5767172",
   "metadata": {
    "height": 149,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: support_articles/FS Text\\Administrator tools.docx\n",
      "Getting tools for paper: support_articles/FS Text\\Audio segments.docx\n",
      "Getting tools for paper: support_articles/FS Text\\Classification and topic model data processing differences.docx\n",
      "Getting tools for paper: support_articles/FS Text\\FS Text application overview.docx\n",
      "Getting tools for paper: support_articles/FS Text\\FS TEXT APPLICATION тАУ USER TYPES, ADMINISTRATING AND CREATING.docx\n",
      "Getting tools for paper: support_articles/FS Text\\FStext_articles_structure.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to add models into production environment.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to assess a classification model.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to change models attached to production environment.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to create a classification model.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to create a keyword model.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to create a topic model.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to use the API for FS Text application.docx\n",
      "Getting tools for paper: support_articles/FS Text\\How to use the FS Text application for data labelling.docx\n",
      "Getting tools for paper: support_articles/FS Text\\Language detection.docx\n",
      "Getting tools for paper: support_articles/FS Text\\Lemmatization.docx\n",
      "Getting tools for paper: support_articles/FS Text\\Text anonymization with FS Text.docx\n",
      "Getting tools for paper: support_articles/FS Text\\What affects ASR quality.docx\n",
      "Getting tools for paper: support_articles/FS Text\\What affects classification accuracy.docx\n",
      "Getting tools for paper: support_articles/FS Text\\What aspects to think about before model training.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Adding a channel.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Adding evaluation tasks to a channel.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Call price тАУ evaluation and analysis.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Channels view.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Configuring regular email reports.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Quality Assurance view.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\ADMIN Repetitive calls тАУ evaluation and analysis.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Anonymisation of conversations.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Consent-based conversation analytics.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Email reports.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\RELEASE NOTES FOR VERSION 1.11.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Time-limited data access.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\User stats draft KB.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Users view┬а- adding, editing and viewing user information.docx\n",
      "Getting tools for paper: support_articles/Topic Admin menu\\Using, creating, and editing Lexicons.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\ADMIN Editing Agent and Team dashboards.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\ADMIN How to add a Team.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\ADMIN How to add an Agent to a Team.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\ADMIN How to add an Agent.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\ADMIN How to move Agent from one Team to another.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\Agent view.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\Introduction to Agent and Teams menu.docx\n",
      "Getting tools for paper: support_articles/TOPIC Agents and Teams\\Teams view.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\ADMIN Additional chart creation options for admin users (beta).docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Agent and Customer specific evaluations update in version 1.10.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Aggregating data and group тАЬOtherтАЭ.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Call features evaluations, explanations, use cases.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Chart creation overview.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Chat features evaluations, explanations, use cases.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Comparison to the preceding period.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to apply filters during chart creation.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Area charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create bar charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Big number charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Concordance charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Line charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Pie charts.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Tables.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Text samples.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to create Word clouds.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to use different output types for chart creation.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\How to visualize multiple choice answers for feedback analysis.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Introduction to chart types.docx\n",
      "Getting tools for paper: support_articles/Topic Chart creation\\Trending words - a new chart type.docx\n",
      "Getting tools for paper: support_articles/Topic Conversations\\ADMIN How to edit the Conversations views.docx\n",
      "Getting tools for paper: support_articles/Topic Conversations\\Introduction to the Conversations menu.docx\n",
      "Getting tools for paper: support_articles/TOPIC Customers\\ADMIN How to update the Customer Dashboard.docx\n",
      "Getting tools for paper: support_articles/TOPIC Customers\\How to update the Customer information.docx\n",
      "Getting tools for paper: support_articles/TOPIC Customers\\Introduction to Customers menu.docx\n",
      "Getting tools for paper: support_articles/TOPIC Discover\\ADMIN Editing evaluations shown in the Enriched Data Points.docx\n",
      "Getting tools for paper: support_articles/TOPIC Discover\\Enriched Data Points.docx\n",
      "Getting tools for paper: support_articles/TOPIC Discover\\Introduction to Discover menu.docx\n",
      "Getting tools for paper: support_articles/TOPIC Getting Started\\Getting started with Leadstream.docx\n",
      "Getting tools for paper: support_articles/TOPIC Getting Started\\Support, questions, and bug reports.docx\n",
      "Getting tools for paper: support_articles/Topic Insights\\ADMIN Editing the Insights Stories.docx\n",
      "Getting tools for paper: support_articles/Topic Insights\\ADMIN Publishing and unpublishing Stories to the Insights menu.docx\n",
      "Getting tools for paper: support_articles/Topic Insights\\Introduction to Insights menu.docx\n",
      "Getting tools for paper: support_articles/Topic Quality Score\\Automated Quality Score components and scoring.docx\n",
      "Getting tools for paper: support_articles/Topic Quality Score\\Quality score articles initial ideas.docx\n",
      "Getting tools for paper: support_articles/Topic Quality Score\\WHAT IS THE AUTOMATED QUALITY SCORE.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\ADMIN Activities in the event detail view.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Changing the language of a call.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\CREATING SEARCHES тАУ KEYWORDS, FIELDS AND FILTERS.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: support_articles/Topic Search and search results\\Event detail view.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Event quick view.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Examples of search queries.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\How to search.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\How to view search results.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Listening to a call.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Normalized time тАУ searching from a particular part in a call or chat.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Searching using a phone number.docx\n",
      "Getting tools for paper: support_articles/Topic Search and search results\\Sharing a conversation with a colleague.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Best practices for Story creation.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Duplicating and sharing Storyboards.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Duplicating or making a personal copy of a Story shared with you.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Global filter.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\How to name and manage Stories for an easier overview.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Introduction to Stories.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Sharing stories with colleagues.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Viewing and editing Story sharing settings.docx\n",
      "Getting tools for paper: support_articles/Topic Story\\Working on a Story with a colleague.docx\n",
      "Getting tools for paper: support_articles/TOPIC Tasks\\ADMIN How to assign tasks to an Agent or a Team.docx\n",
      "Getting tools for paper: support_articles/TOPIC Tasks\\ADMIN How to create Rules and tie them to Actions.docx\n",
      "Getting tools for paper: support_articles/TOPIC Tasks\\ADMIN How to set up email notifications for fast reactions and review of events.docx\n",
      "Getting tools for paper: support_articles/TOPIC Tasks\\How to use the Tasks Overview view.docx\n",
      "Getting tools for paper: support_articles/TOPIC Tasks\\Introduction to Tasks.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\6 steps of data analysis.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Customers being put on hold тАУ finding the calls where it happens and analysing them.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Give you Agents access to Leadstream тАУ a few use cases.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\How to get started with analysing customer feedback.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\How to go from having data to having actionable insights.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\How to use customer conversation data of different periods for a variety of use cases.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Searching for тАЬnegativeтАЭ vocabulary тАУ how to find issues.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Using a focus project to reach a common goal with the team, department, or company.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Using customer conversations or feedback for process or product improvement prioritisation.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\When is analysis ready.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Why and how to find calls with a high share of silence.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Why do customers contact us.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Why should you analyse customer feedback.docx\n",
      "Getting tools for paper: support_articles/TOPIC Use cases\\Why use AI models in classifying customer conversations.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Additional apps.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Administrator role and best practices.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\agent role and personal view.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Calendar 1.9.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Calendar.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Changing the password.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Logging in to the application.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\Not able to log in.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\User roles and permissions.docx\n",
      "Getting tools for paper: support_articles/Topic User related settings\\User Settings.docx\n"
     ]
    }
   ],
   "source": [
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, sanitize_names(Path(paper).stem))\n",
    "    if len(vector_tool.metadata.name)>64:\n",
    "        resp=llm.complete(f'please make this function name shorter so that it would have only up to 60 or less characters {vector_tool.metadata.name}')\n",
    "        vector_tool.metadata.name=resp.text[:64]\n",
    "    if len(summary_tool.metadata.name)>64:\n",
    "        resp=llm.complete(f'please make this function name shorter so that it would have only up to 60 or less characters {summary_tool.metadata.name}')\n",
    "        summary_tool.metadata.name=resp.text[:64]\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35d52c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extend the Agent with Tool Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20154923-873e-4941-9a3a-4926ab5f9b8c",
   "metadata": {
    "height": 30,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7730c4f9-b96b-4e1d-bfde-65fab1d2173f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fb11768",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "32\n",
      "26\n",
      "27\n",
      "39\n",
      "41\n",
      "40\n",
      "41\n",
      "37\n",
      "46\n",
      "37\n",
      "38\n",
      "57\n",
      "58\n",
      "48\n",
      "49\n",
      "37\n",
      "32\n",
      "48\n",
      "49\n",
      "41\n",
      "42\n",
      "39\n",
      "40\n",
      "54\n",
      "55\n",
      "34\n",
      "47\n",
      "30\n",
      "31\n",
      "25\n",
      "26\n",
      "43\n",
      "44\n",
      "36\n",
      "37\n",
      "48\n",
      "49\n",
      "61\n",
      "62\n",
      "34\n",
      "35\n",
      "54\n",
      "55\n",
      "52\n",
      "53\n",
      "31\n",
      "32\n",
      "51\n",
      "52\n",
      "40\n",
      "41\n",
      "58\n",
      "59\n",
      "42\n",
      "43\n",
      "48\n",
      "49\n",
      "25\n",
      "26\n",
      "42\n",
      "43\n",
      "36\n",
      "37\n",
      "31\n",
      "32\n",
      "28\n",
      "33\n",
      "47\n",
      "48\n",
      "51\n",
      "52\n",
      "35\n",
      "36\n",
      "47\n",
      "48\n",
      "37\n",
      "38\n",
      "60\n",
      "61\n",
      "22\n",
      "23\n",
      "48\n",
      "49\n",
      "22\n",
      "23\n",
      "47\n",
      "37\n",
      "36\n",
      "56\n",
      "45\n",
      "46\n",
      "60\n",
      "61\n",
      "35\n",
      "36\n",
      "60\n",
      "61\n",
      "46\n",
      "47\n",
      "54\n",
      "55\n",
      "37\n",
      "38\n",
      "36\n",
      "37\n",
      "43\n",
      "44\n",
      "44\n",
      "45\n",
      "37\n",
      "38\n",
      "36\n",
      "37\n",
      "32\n",
      "33\n",
      "38\n",
      "39\n",
      "37\n",
      "38\n",
      "64\n",
      "40\n",
      "51\n",
      "38\n",
      "39\n",
      "40\n",
      "43\n",
      "44\n",
      "53\n",
      "54\n",
      "50\n",
      "51\n",
      "54\n",
      "55\n",
      "50\n",
      "51\n",
      "42\n",
      "43\n",
      "47\n",
      "59\n",
      "32\n",
      "33\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "46\n",
      "47\n",
      "43\n",
      "50\n",
      "41\n",
      "42\n",
      "58\n",
      "59\n",
      "48\n",
      "49\n",
      "47\n",
      "48\n",
      "53\n",
      "54\n",
      "43\n",
      "44\n",
      "57\n",
      "58\n",
      "29\n",
      "30\n",
      "28\n",
      "29\n",
      "38\n",
      "39\n",
      "25\n",
      "26\n",
      "38\n",
      "39\n",
      "31\n",
      "32\n",
      "60\n",
      "61\n",
      "42\n",
      "43\n",
      "51\n",
      "52\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "29\n",
      "18\n",
      "25\n",
      "26\n",
      "44\n",
      "39\n",
      "35\n",
      "36\n",
      "43\n",
      "44\n",
      "54\n",
      "55\n",
      "47\n",
      "48\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "64\n",
      "64\n",
      "46\n",
      "47\n",
      "33\n",
      "34\n",
      "36\n",
      "37\n",
      "35\n",
      "31\n",
      "64\n",
      "50\n",
      "63\n",
      "64\n",
      "38\n",
      "26\n",
      "60\n",
      "64\n",
      "64\n",
      "33\n",
      "61\n",
      "63\n",
      "44\n",
      "64\n",
      "34\n",
      "35\n",
      "35\n",
      "36\n",
      "39\n",
      "40\n",
      "52\n",
      "53\n",
      "39\n",
      "42\n",
      "27\n",
      "28\n",
      "49\n",
      "50\n",
      "40\n",
      "41\n",
      "24\n",
      "25\n",
      "20\n",
      "21\n",
      "33\n",
      "34\n",
      "41\n",
      "42\n",
      "30\n",
      "31\n",
      "38\n",
      "39\n",
      "25\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for tool in all_tools:\n",
    "    print(len(tool.metadata.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64cfae0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summary_tool_Class_topic_processing_diffs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tools[5].metadata.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671582f9-70d7-4a8f-b813-58b2a068ca72",
   "metadata": {
    "height": 149,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bec83e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obj_index.persist(persist_dir='object_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f7ccec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ObjectIndex.from_persist_dir(persist_dir='object_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3929882-e9dc-46ca-b495-53e3ed60340e",
   "metadata": {
    "height": 30,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba9cfecd-fe14-4da8-b9ba-b3d485d98a03",
   "metadata": {
    "height": 64,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tools = obj_retriever.retrieve(\n",
    "    \"how to build a wordcloud?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "773d1d7c-66a7-4618-bd73-81bedfdb3f2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llama_index.core.tools.query_engine.QueryEngineTool at 0x27a512f4cd0>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x27a513496a0>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x27a515507f0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cc0a0b6-9858-4348-9ae0-1cd4160f3fb7",
   "metadata": {
    "height": 268,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given articles.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge. Say if topic is not mentioned in the articles\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82fbc-7090-436d-b8a6-833fc402bb59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## use agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a250cf1a-e011-4994-bcca-4e0294f20864",
   "metadata": {
    "height": 98,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step dd84c66f-e7fe-43d9-b6ac-4bf273b07d50. Step input: how to create rules?\n",
      "Added user message to memory: how to create rules?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_ADMIN_How_to_create_Rules_and_tie_them_to_Actions with args: {\"input\": \"how to create rules\"}\n",
      "=== Function Output ===\n",
      "To create rules, first, go to the Rules view in the Tasks menu and click on the plus sign to set up a new rule. Fill in the Rule Settings with the name and choose the Action to tie the rule to. You can set the \"Continue\" field to yes or no, indicating whether other rules should be performed if the conditions are met. Add filters to set up specific criteria for the rule, such as using filters like \"text contains\" to query specific fields like overall event text or actor. Apply filters as needed to ensure the rule captures the desired events. Regularly review and manage the rules list to remove any unnecessary rules and actions for clarity and efficiency.\n",
      "> Running step 5dccb040-fa99-46d2-bd2b-4cb24fd9f3d6. Step input: None\n",
      "=== LLM Response ===\n",
      "To create rules, you can follow these steps:\n",
      "1. Go to the Rules view in the Tasks menu.\n",
      "2. Click on the plus sign to set up a new rule.\n",
      "3. Fill in the Rule Settings with the name and choose the Action to tie the rule to.\n",
      "4. Set the \"Continue\" field to yes or no, indicating whether other rules should be performed if the conditions are met.\n",
      "5. Add filters to set up specific criteria for the rule, such as using filters like \"text contains\" to query specific fields like overall event text or actor.\n",
      "6. Apply filters as needed to ensure the rule captures the desired events.\n",
      "7. Regularly review and manage the rules list to remove any unnecessary rules and actions for clarity and efficiency.\n",
      "assistant: To create rules, you can follow these steps:\n",
      "1. Go to the Rules view in the Tasks menu.\n",
      "2. Click on the plus sign to set up a new rule.\n",
      "3. Fill in the Rule Settings with the name and choose the Action to tie the rule to.\n",
      "4. Set the \"Continue\" field to yes or no, indicating whether other rules should be performed if the conditions are met.\n",
      "5. Add filters to set up specific criteria for the rule, such as using filters like \"text contains\" to query specific fields like overall event text or actor.\n",
      "6. Apply filters as needed to ensure the rule captures the desired events.\n",
      "7. Regularly review and manage the rules list to remove any unnecessary rules and actions for clarity and efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"how to create rules?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8084c8cb-98ed-4835-aaa4-5b0c7254be6d",
   "metadata": {
    "height": 81,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c43c7373-f66e-4217-bfce-012520c7cc0e. Step input: what I need to train topic model?\n",
      "Added user message to memory: what I need to train topic model?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_What_aspects_to_think_about_before_model_training with args: {\"input\": \"What do I need to train a topic model?\"}\n",
      "=== Function Output ===\n",
      "To train a topic model, you need texts as input. It is important to have at least hundreds of samples of data, with more data being preferable for better results. If you do not have any labelled data, starting with a topic model is recommended. The topic model requires a sufficient amount of texts to work effectively, ideally more than 1000 texts for more granular topic discovery.\n",
      "> Running step 3f23f3f1-64f0-449c-8b17-7d78eabd148b. Step input: None\n",
      "=== LLM Response ===\n",
      "To train a topic model, you need texts as input. It is important to have at least hundreds of samples of data, with more data being preferable for better results. If you do not have any labelled data, starting with a topic model is recommended. The topic model requires a sufficient amount of texts to work effectively, ideally more than 1000 texts for more granular topic discovery.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"what I need to train topic model?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da22e3ab-c216-4d4b-93a2-653d5788402a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e58ba026-0559-4819-b28f-6292db25cc6a. Step input: How can I change the time period from days to weeks when making charts?\n",
      "Added user message to memory: How can I change the time period from days to weeks when making charts?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_apply_filters_during_chart_creation with args: {\"input\": \"Change time period from days to weeks when making charts\"}\n",
      "=== Function Output ===\n",
      "To change the time period from days to weeks when making charts, you can utilize the filters available during chart creation. By specifying the desired time frame in terms of weeks instead of days, you can adjust the results displayed in the chart accordingly. This flexibility allows you to customize the chart output based on your specific requirements, providing a more tailored visualization of the data.\n",
      "> Running step 77675b51-483a-4bc4-9049-8f0427556916. Step input: None\n",
      "=== LLM Response ===\n",
      "To change the time period from days to weeks when making charts, you can utilize the filters available during chart creation. By specifying the desired time frame in terms of weeks instead of days, you can adjust the results displayed in the chart accordingly. This flexibility allows you to customize the chart output based on your specific requirements, providing a more tailored visualization of the data.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"How can I change the time period from days to weeks when making charts?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f32964b-d9eb-4749-9d18-bc6c721cf042",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step a02dcb75-2e87-4771-851e-c8353681998a. Step input: What is new in version 1.11?\n",
      "Added user message to memory: What is new in version 1.11?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_RELEASE_NOTES_FOR_VERSION_1_11 with args: {\"input\": \"What is new in version 1.11?\"}\n",
      "=== Function Output ===\n",
      "In version 1.11, two new functions have been introduced. The first one is consent-based conversation analytics, which allows individuals to choose whether their data is used for analysis purposes. The second new function is time-limited data access, which enables setting time-based limits for accessing data in the Leadstream application.\n",
      "> Running step 8faa320c-2403-475d-a5c2-938bb42dcfec. Step input: None\n",
      "=== LLM Response ===\n",
      "In version 1.11, two new functions have been introduced: consent-based conversation analytics and time-limited data access.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"What is new in version 1.11?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae760d3c-22cc-4443-af5d-bc8b08b77eb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step fa2e4746-4c0c-4a81-99bc-cec003dc3f79. Step input: Can I use LLMs in the platform?\n",
      "Added user message to memory: Can I use LLMs in the platform?\n",
      "=== LLM Response ===\n",
      "I will check the articles to find information about using LLMs in the platform.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Language_detection with args: {\"input\": \"LLMs in the platform\"}\n",
      "=== Function Output ===\n",
      "The platform does not mention LLMs in the context provided.\n",
      "> Running step f167144d-99cc-49e9-a627-365df89287ed. Step input: None\n",
      "=== LLM Response ===\n",
      "The platform does not mention the use of LLMs in the context provided.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Can I use LLMs in the platform?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "098b244a-5ab7-46ac-b32a-76836ab09ae4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 01565f15-bae8-4d95-8d48-677d24b6194b. Step input: Can I fly to the moon with the platform?\n",
      "Added user message to memory: Can I fly to the moon with the platform?\n",
      "=== LLM Response ===\n",
      "I'm not sure what you mean by \"the platform.\" Could you please provide more context or clarify your question so I can better assist you?\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Can I fly to the moon with the platform?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5415dc48-cec1-444b-8935-6fad634ec149",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 10ac9bed-3c9c-45ca-b2ce-c893d31084ec. Step input: Can I edit transcript in the platform?\n",
      "Added user message to memory: Can I edit transcript in the platform?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_ADMIN_How_to_edit_the_Conversations_views with args: {\"input\": \"Can I edit transcript in the platform?\"}\n",
      "=== Function Output ===\n",
      "Yes, you can edit the transcript in the platform.\n",
      "> Running step a40dc606-a05f-497e-8e45-02926f33186e. Step input: None\n",
      "=== LLM Response ===\n",
      "Yes, you can edit the transcript in the platform.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Can I edit transcript in the platform?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cca8a279-eae6-41d1-b83d-bb308f4360e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 95c8eab6-4b5d-4ea5-9419-c7fb74c3b0f2. Step input: please give me a detailed guide how to edit transcript\n",
      "Added user message to memory: please give me a detailed guide how to edit transcript\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_ADMIN_How_to_edit_the_Conversations_views with args: {\"input\": \"detailed guide how to edit transcript\"}\n",
      "=== Function Output ===\n",
      "The article provides a detailed guide on how an Administrator user can edit the Dashboard view in the Conversations menu. It explains that the Administrator can adjust the Dashboard view based on the company's needs by accessing the Story settings cogwheel in the top right corner of the page. By selecting \"Edit this template,\" the Administrator can then make changes to all charts within the Dashboard, add new ones, delete them, add comments, and more. It emphasizes the importance of considering user permissions when making changes and suggests creating separate Storyboards if needed. The article also mentions gathering feedback from users to ensure the best possible result.\n",
      "> Running step 50b831aa-775d-4f64-b53d-287e9adb8afc. Step input: None\n",
      "=== LLM Response ===\n",
      "The detailed guide on editing transcripts involves an Administrator user adjusting the Dashboard view in the Conversations menu. The process includes accessing the Story settings cogwheel, selecting \"Edit this template,\" making changes to charts, adding new ones, deleting elements, adding comments, and more. It highlights the importance of considering user permissions, creating separate Storyboards if necessary, and gathering feedback from users for the best outcome.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"please give me a detailed guide how to edit transcript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06110e19-66cb-48e5-aa41-74800c316528",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## try with trulens eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2c1d562-9cba-4a64-807b-404779c6a819",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddf16c41-d6d7-4852-b3a0-5187e2fc9f44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import OpenAI as fOpenAI\n",
    "\n",
    "provider = fOpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268e459",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b61d93f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback\n",
    "\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cec44f59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import TruLlama\n",
    "\n",
    "context_selection = TruLlama.select_source_nodes().node.text\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "996c2f29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RistoHinno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons,\n",
    "             name=\"Groundedness\"\n",
    "            )\n",
    "    .on(context_selection)\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349fc775",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load example questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "091bad2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('data/eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b256239",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step adbf8d3d-aede-4159-a538-c646fc19949f. Step input: how can I make topic model?\n",
      "Added user message to memory: how can I make topic model?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_create_a_topic_model with args: {\"input\": \"how can I make topic model?\"}\n",
      "=== Function Output ===\n",
      "To create a topic model using the FS Text application, you can follow these steps:\n",
      "\n",
      "1. Log in to the FS Text application and choose the Model builder menu item.\n",
      "2. In the Model builder view, click on the New model option in the left-hand menu.\n",
      "3. Fill in the form for your new model with a descriptive name, description, business purpose, and language. Choose Topic model as your Model type and press Create model.\n",
      "4. Upload your data using an Excel file in the Model and data view. Ensure all data is included in one Excel file.\n",
      "5. Review the data to validate if it was uploaded correctly in the Review data view.\n",
      "6. Add words to be removed in the Cleaners tab, such as stopwords, in a specific format.\n",
      "7. Clean the data in the Clean data area, which involves processes like lowercasing text, removing punctuation, and lemmatization.\n",
      "8. Generate ngrams in the Ngrams tab to grasp common terms in the text.\n",
      "9. Start the model training process by providing the number of topics and clicking on the Train model button in the Train model view.\n",
      "10. Review the training experiments and adjust the number of topics if needed in the Experiments view.\n",
      "11. Test the trained model by writing/copying a text in the Predict view.\n",
      "12. Finish up by iterating through cleaning and training rounds, ensuring the topics make sense and experimenting with different numbers of topics until you achieve informative results.\n",
      "> Running step 689a7dee-7fab-450d-878a-8eedca93bb76. Step input: None\n",
      "=== LLM Response ===\n",
      "To create a topic model using the FS Text application, you can follow these steps:\n",
      "\n",
      "1. Log in to the FS Text application and choose the Model builder menu item.\n",
      "2. In the Model builder view, click on the New model option in the left-hand menu.\n",
      "3. Fill in the form for your new model with a descriptive name, description, business purpose, and language. Choose Topic model as your Model type and press Create model.\n",
      "4. Upload your data using an Excel file in the Model and data view. Ensure all data is included in one Excel file.\n",
      "5. Review the data to validate if it was uploaded correctly in the Review data view.\n",
      "6. Add words to be removed in the Cleaners tab, such as stopwords, in a specific format.\n",
      "7. Clean the data in the Clean data area, which involves processes like lowercasing text, removing punctuation, and lemmatization.\n",
      "8. Generate ngrams in the Ngrams tab to grasp common terms in the text.\n",
      "9. Start the model training process by providing the number of topics and clicking on the Train model button in the Train model view.\n",
      "10. Review the training experiments and adjust the number of topics if needed in the Experiments view.\n",
      "11. Test the trained model by writing/copying a text in the Predict view.\n",
      "12. Finish up by iterating through cleaning and training rounds, ensuring the topics make sense and experimenting with different numbers of topics until you achieve informative results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32372a10e0345cdbf4148b9b271c840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c01d5827-57ff-4755-80a7-8ba4fc4aa486. Step input: how much data is needed for topic model?\n",
      "Added user message to memory: how much data is needed for topic model?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_create_a_topic_model with args: {\"input\": \"how much data is needed for topic model\"}\n",
      "=== Function Output ===\n",
      "The data needed for creating a topic model can vary depending on the specific use case and the complexity of the topics being analyzed. Typically, a topic model can be created with a few hundred to a few thousand texts as input data. It is important to have a sufficient amount of data to ensure that the model can identify meaningful topics and patterns within the text.\n",
      "> Running step 61bbaad5-74bf-437b-9340-6d0873a5d81c. Step input: None\n",
      "=== LLM Response ===\n",
      "The data needed for creating a topic model can vary, but typically a few hundred to a few thousand texts are required as input data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424eece67c5346cd854f7d3f65ad0fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 9921c84d-697b-42d8-a5fc-61b96f1af47e. Step input: can LLMs be used for topic models?\n",
      "Added user message to memory: can LLMs be used for topic models?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_create_a_topic_model with args: {\"input\": \"LLMs\"}\n",
      "=== Function Output ===\n",
      "LLMs are not directly mentioned in the provided context information.\n",
      "> Running step 58b977ac-a6b7-48ac-a072-0f547907d8d1. Step input: None\n",
      "=== LLM Response ===\n",
      "LLMs (Large Language Models) are not directly mentioned in the context of creating topic models. If you need more specific information on how LLMs can be used for topic models, please provide additional details or context for a more accurate response.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844df0497ce44029b2083b4c3ec3d1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step f1f5c37b-6c62-4085-bbdc-8f3cc39a262a. Step input: what are the steps for training topic model?\n",
      "Added user message to memory: what are the steps for training topic model?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_create_a_topic_model with args: {\"input\": \"steps for training topic model\"}\n",
      "=== Function Output ===\n",
      "To train a topic model using the FS Text application, you should first log in and access the Model builder menu. Then, proceed by creating a new model by filling in the necessary details like a descriptive name, description, business purpose, and language. Choose \"Topic model\" as the Model type and create the model. After creating the model, upload your data in the Model and data view using an Excel file. Ensure that all data is included in one Excel file. Review the data in the Review data view to validate if the correct data was uploaded in the correct format.\n",
      "\n",
      "Next, in the Cleaners tab, add words that need to be removed from the model, such as stopwords. You can divide removable words into categories like Custom words, Custom Synonyms, Custom Stopwords, or add them all to the Custom Words Remove field. After cleaning the data, proceed to the Ngrams tab to generate ngrams for common terms in the text.\n",
      "\n",
      "Once the data is cleaned and ngrams are generated, move to the Train model view to start the model training process. Provide the number of topics and initiate the training process. Monitor the training progress in the Logs under Training logs. After training, review the results in the Experiments view, where you can see detailed results, topics, and bubble charts. Evaluate the topics, adjust as needed, and name the topics accordingly.\n",
      "\n",
      "Finally, test the trained model in the Predict view by writing or uploading text to predict its topic. The topic model training process typically involves multiple cleaning and training rounds to refine the model for accurate topic classification. It is essential to ensure that the topics make sense and are distinct.\n",
      "> Running step e4e3c295-7241-4fb6-bd18-2e1b8630de57. Step input: None\n",
      "=== LLM Response ===\n",
      "Training a topic model involves several steps. Here is an overview of the process:\n",
      "\n",
      "1. Log in to the FS Text application and access the Model builder menu.\n",
      "2. Create a new model by providing details like name, description, business purpose, and language.\n",
      "3. Choose \"Topic model\" as the Model type and create the model.\n",
      "4. Upload data in the Model and data view using an Excel file.\n",
      "5. Review the data in the Review data view to validate the correct format and content.\n",
      "6. Clean the data by removing stopwords and other unnecessary words in the Cleaners tab.\n",
      "7. Generate ngrams for common terms in the text in the Ngrams tab.\n",
      "8. Train the model by specifying the number of topics and initiating the training process in the Train model view.\n",
      "9. Monitor the training progress in the Logs under Training logs.\n",
      "10. Review the results in the Experiments view to evaluate topics, adjust as needed, and name them accordingly.\n",
      "11. Test the trained model in the Predict view by inputting text to predict its topic.\n",
      "\n",
      "The training process may involve multiple rounds of cleaning and training to refine the model for accurate topic classification. It is crucial to ensure that the topics generated make sense and are distinct.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820940b669e943b2adaa34309bba0e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step f040f1fd-04bb-4331-ab19-23114a7ce3fe. Step input: What kind of analysis can I make in the platform?\n",
      "Added user message to memory: What kind of analysis can I make in the platform?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Customer_conversation_data_analysis_for_various_use with args: {\"input\": \"What kind of analysis can I make in the platform?\"}\n",
      "=== Function Output ===\n",
      "You can conduct various types of analysis on the platform, including real-time conversation analysis, short-term monitoring and evaluation, medium-term trend tracking, long-term performance reviews, competitor analysis, customer satisfaction trend analysis, product/service feedback analysis, conversation topic analysis, seasonal trend identification, customer lifecycle analysis, long-term strategy development, customer loyalty analysis, predictive analytics, and reclamation and complaint handling.\n",
      "> Running step e186b464-a04d-42a2-8f42-3e839ce1e6b1. Step input: None\n",
      "=== LLM Response ===\n",
      "You can conduct various types of analysis on the platform, including real-time conversation analysis, short-term monitoring and evaluation, medium-term trend tracking, long-term performance reviews, competitor analysis, customer satisfaction trend analysis, product/service feedback analysis, conversation topic analysis, seasonal trend identification, customer lifecycle analysis, long-term strategy development, customer loyalty analysis, predictive analytics, and reclamation and complaint handling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8cecb4c9654fada9bec43eb432a90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e191a67c-59a3-4e89-95cd-97f10d3bb77f. Step input: how to find unwanted calls?\n",
      "Added user message to memory: how to find unwanted calls?\n",
      "=== LLM Response ===\n",
      "To find unwanted calls, you can follow these steps:\n",
      "\n",
      "1. **Check Call Logs**: Review your call logs to identify numbers that you don't recognize or have a history of unwanted calls.\n",
      "\n",
      "2. **Use Call Blocking Apps**: Install call blocking apps on your phone that can automatically detect and block spam calls.\n",
      "\n",
      "3. **Register with Do Not Call Registry**: Register your phone number with the national \"Do Not Call\" registry to reduce telemarketing calls.\n",
      "\n",
      "4. **Report Unwanted Calls**: Report unwanted calls to your phone carrier or the Federal Trade Commission (FTC) to help track and stop spam callers.\n",
      "\n",
      "5. **Avoid Answering Unknown Numbers**: If you receive a call from an unknown number, avoid answering it to prevent unwanted calls.\n",
      "\n",
      "6. **Enable Call Screening**: Use call screening features on your phone to filter out unwanted calls based on pre-defined criteria.\n",
      "\n",
      "By following these steps, you can effectively identify and reduce unwanted calls.\n",
      "> Running step 4a40e6b6-a353-4dee-a20f-b41fd8045bfd. Step input: what are options for sentiment detection in call transcripts?\n",
      "Added user message to memory: what are options for sentiment detection in call transcripts?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_AI_classify_customer_conversations with args: {\"input\": \"options for sentiment detection in call transcripts\"}\n",
      "=== Function Output ===\n",
      "The article discusses using AI models to classify customer conversations, specifically mentioning supervised models for topics and sentiment. Supervised models are created with specific rules and guidelines for classification, making them accurate but requiring human labeling which can be time-consuming. On the other hand, unsupervised models do not require human labeling and can find topics based on word frequencies, making them quicker to create but potentially harder to interpret. Both types have their pros and cons, with supervised models being accurate and guided, while unsupervised models can pick up patterns that may not have been initially considered.\n",
      "> Running step aaf20d88-d8d3-45d5-8a2e-7f8e4ef38743. Step input: None\n",
      "=== LLM Response ===\n",
      "The options for sentiment detection in call transcripts include using supervised AI models that are accurate but require human labeling, and unsupervised AI models that do not need human labeling but may be harder to interpret. Supervised models are guided and accurate, while unsupervised models can identify patterns that may not have been initially considered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed12dee56c74530a486c1cc879181dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 3105295c-1c35-4b71-941e-aabfc9f2aac7. Step input: where should I start if I am total beginner in using the application?\n",
      "Added user message to memory: where should I start if I am total beginner in using the application?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_get_started_with_analysing_customer_feedback with args: {\"input\": \"total beginner in using the application\"}\n",
      "=== Function Output ===\n",
      "The article provides a step-by-step guide on how to get started with analyzing customer feedback using the Leadstream application. It explains the importance of understanding the data available, creating an overview, setting goals or questions, validating and measuring hypotheses, and monitoring changes over time. By following these steps, a total beginner in using the application can gradually learn how to effectively analyze customer feedback and derive insights to improve customer experience.\n",
      "> Running step ae5dd006-e432-4307-a9fd-e16b2412454f. Step input: None\n",
      "=== LLM Response ===\n",
      "If you are a total beginner in using the application, you should start by understanding the data available, creating an overview, setting goals or questions, validating and measuring hypotheses, and monitoring changes over time. This step-by-step guide will help you get started with analyzing customer feedback effectively.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521fb052365242a5bec2ec2dc19cca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 5a610e2a-efee-4ae7-b548-25b212ba5c75. Step input: can I download data into excel file?\n",
      "Added user message to memory: can I download data into excel file?\n",
      "=== LLM Response ===\n",
      "To assist you with downloading data into an Excel file, I will first need to understand the context or source of the data you are referring to. Could you please provide more details about the data source or the specific data you would like to download into an Excel file?\n",
      "> Running step 88949921-b431-4ec0-baa0-8c81288d98f7. Step input: anonymization is not working correctly, some names are not removed. What should I do?\n",
      "Added user message to memory: anonymization is not working correctly, some names are not removed. What should I do?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Anonymisation_of_conversations with args: {\"input\": \"anonymization is not working correctly, some names are not removed. What should I do?\"}\n",
      "=== Function Output ===\n",
      "To address the issue where some names are not being removed during anonymization, you should first review the anonymization settings in the Leadstream application. Check if the names that are not being removed are configured correctly in the anonymization rules. Ensure that the names are included in the list of PII (Personally Identifiable Information) that should be anonymized. If the issue persists, consider reaching out to your Customer Success Manager for further assistance in adjusting the anonymization settings to ensure all sensitive information, including names, is properly masked in the conversations.\n",
      "> Running step 80532723-26a4-4927-9d6a-0a3a71adcb5b. Step input: None\n",
      "=== LLM Response ===\n",
      "To address the issue where some names are not being removed during anonymization, you should first review the anonymization settings in the Leadstream application. Check if the names that are not being removed are configured correctly in the anonymization rules. Ensure that the names are included in the list of PII (Personally Identifiable Information) that should be anonymized. If the issue persists, consider reaching out to your Customer Success Manager for further assistance in adjusting the anonymization settings to ensure all sensitive information, including names, is properly masked in the conversations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a97b783c8394f9ca269b468a5d3f56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_relevances=[]\n",
    "groundednesses=[]\n",
    "context_relevances=[]\n",
    "contexts=[]\n",
    "answers=[]\n",
    "\n",
    "for question in eval_questions:\n",
    "    response = agent.query(question)\n",
    "    answers.append(response.response)\n",
    "    \n",
    "    answer_relevances.append(f_qa_relevance(question, response.response))\n",
    "    \n",
    "    context=' '.join([t.text for t in response.source_nodes])\n",
    "       \n",
    "    contexts.append(context)\n",
    "    context_relevances.append(f_qs_relevance(question, context))\n",
    "    \n",
    "    if context=='':\n",
    "        groundednesses.append(({'statement_0': 0},\n",
    "                              {'reasons': 'no_text'}))\n",
    "    else:\n",
    "        groundednesses.append(f_groundedness(context, response.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abda7ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## fromat results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd27fd61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ar=pd.DataFrame(answer_relevances)\n",
    "df_ar.columns=['answer_relevance_score','relevance_reason']\n",
    "# df_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7c6e38e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_grounded_scores(scores, use_median=False):\n",
    "    scores_all=[]\n",
    "    for key, value in scores.items():\n",
    "        scores_all.append(value)\n",
    "    if use_median:\n",
    "        return np.median(scores_all)\n",
    "    return np.mean(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17401a58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_=pd.DataFrame(groundednesses)\n",
    "df_.columns=['ground_scores','ground_reason']\n",
    "df_['ground_score']=df_.ground_scores.apply(lambda x: get_grounded_scores(x))\n",
    "\n",
    "df_results=pd.concat([df_ar, df_], axis=1)\n",
    "df_results['context_relevance_score']=context_relevances\n",
    "df_results['question']=eval_questions\n",
    "df_results['answer']=answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df6e9080",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_relevance_score</th>\n",
       "      <th>ground_score</th>\n",
       "      <th>context_relevance_score</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>how can I make topic model?</td>\n",
       "      <td>assistant: To create a topic model using the FS Text application, you can follow these steps:\\n\\n1. Log in to the FS Text application and choose the Model builder menu item.\\n2. In the Model builder view, click on the New model option in the left-hand menu.\\n3. Fill in the form for your new model with a descriptive name, description, business purpose, and language. Choose Topic model as your Model type and press Create model.\\n4. Upload your data using an Excel file in the Model and data view. Ensure all data is included in one Excel file.\\n5. Review the data to validate if it was uploaded correctly in the Review data view.\\n6. Add words to be removed in the Cleaners tab, such as stopwords, in a specific format.\\n7. Clean the data in the Clean data area, which involves processes like lowercasing text, removing punctuation, and lemmatization.\\n8. Generate ngrams in the Ngrams tab to grasp common terms in the text.\\n9. Start the model training process by providing the number of topics and clicking on the Train model button in the Train model view.\\n10. Review the training experiments and adjust the number of topics if needed in the Experiments view.\\n11. Test the trained model by writing/copying a text in the Predict view.\\n12. Finish up by iterating through cleaning and training rounds, ensuring the topics make sense and experimenting with different numbers of topics until you achieve informative results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>how much data is needed for topic model?</td>\n",
       "      <td>assistant: The data needed for creating a topic model can vary, but typically a few hundred to a few thousand texts are required as input data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>can LLMs be used for topic models?</td>\n",
       "      <td>assistant: LLMs (Large Language Models) are not directly mentioned in the context of creating topic models. If you need more specific information on how LLMs can be used for topic models, please provide additional details or context for a more accurate response.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>what are the steps for training topic model?</td>\n",
       "      <td>assistant: Training a topic model involves several steps. Here is an overview of the process:\\n\\n1. Log in to the FS Text application and access the Model builder menu.\\n2. Create a new model by providing details like name, description, business purpose, and language.\\n3. Choose \"Topic model\" as the Model type and create the model.\\n4. Upload data in the Model and data view using an Excel file.\\n5. Review the data in the Review data view to validate the correct format and content.\\n6. Clean the data by removing stopwords and other unnecessary words in the Cleaners tab.\\n7. Generate ngrams for common terms in the text in the Ngrams tab.\\n8. Train the model by specifying the number of topics and initiating the training process in the Train model view.\\n9. Monitor the training progress in the Logs under Training logs.\\n10. Review the results in the Experiments view to evaluate topics, adjust as needed, and name them accordingly.\\n11. Test the trained model in the Predict view by inputting text to predict its topic.\\n\\nThe training process may involve multiple rounds of cleaning and training to refine the model for accurate topic classification. It is crucial to ensure that the topics generated make sense and are distinct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>What kind of analysis can I make in the platform?</td>\n",
       "      <td>assistant: You can conduct various types of analysis on the platform, including real-time conversation analysis, short-term monitoring and evaluation, medium-term trend tracking, long-term performance reviews, competitor analysis, customer satisfaction trend analysis, product/service feedback analysis, conversation topic analysis, seasonal trend identification, customer lifecycle analysis, long-term strategy development, customer loyalty analysis, predictive analytics, and reclamation and complaint handling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>how to find unwanted calls?</td>\n",
       "      <td>assistant: To find unwanted calls, you can follow these steps:\\n\\n1. **Check Call Logs**: Review your call logs to identify numbers that you don't recognize or have a history of unwanted calls.\\n\\n2. **Use Call Blocking Apps**: Install call blocking apps on your phone that can automatically detect and block spam calls.\\n\\n3. **Register with Do Not Call Registry**: Register your phone number with the national \"Do Not Call\" registry to reduce telemarketing calls.\\n\\n4. **Report Unwanted Calls**: Report unwanted calls to your phone carrier or the Federal Trade Commission (FTC) to help track and stop spam callers.\\n\\n5. **Avoid Answering Unknown Numbers**: If you receive a call from an unknown number, avoid answering it to prevent unwanted calls.\\n\\n6. **Enable Call Screening**: Use call screening features on your phone to filter out unwanted calls based on pre-defined criteria.\\n\\nBy following these steps, you can effectively identify and reduce unwanted calls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.4</td>\n",
       "      <td>what are options for sentiment detection in call transcripts?</td>\n",
       "      <td>assistant: The options for sentiment detection in call transcripts include using supervised AI models that are accurate but require human labeling, and unsupervised AI models that do not need human labeling but may be harder to interpret. Supervised models are guided and accurate, while unsupervised models can identify patterns that may not have been initially considered.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.4</td>\n",
       "      <td>where should I start if I am total beginner in using the application?</td>\n",
       "      <td>assistant: If you are a total beginner in using the application, you should start by understanding the data available, creating an overview, setting goals or questions, validating and measuring hypotheses, and monitoring changes over time. This step-by-step guide will help you get started with analyzing customer feedback effectively.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>can I download data into excel file?</td>\n",
       "      <td>assistant: To assist you with downloading data into an Excel file, I will first need to understand the context or source of the data you are referring to. Could you please provide more details about the data source or the specific data you would like to download into an Excel file?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4</td>\n",
       "      <td>anonymization is not working correctly, some names are not removed. What should I do?</td>\n",
       "      <td>assistant: To address the issue where some names are not being removed during anonymization, you should first review the anonymization settings in the Leadstream application. Check if the names that are not being removed are configured correctly in the anonymization rules. Ensure that the names are included in the list of PII (Personally Identifiable Information) that should be anonymized. If the issue persists, consider reaching out to your Customer Success Manager for further assistance in adjusting the anonymization settings to ensure all sensitive information, including names, is properly masked in the conversations.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_relevance_score  ground_score  context_relevance_score  \\\n",
       "0                     0.9          1.00                      0.8   \n",
       "1                     0.9          0.70                      0.4   \n",
       "2                     0.2          0.00                      0.4   \n",
       "3                     1.0          1.00                      0.7   \n",
       "4                     1.0          1.00                      0.8   \n",
       "5                     1.0          0.00                      0.0   \n",
       "6                     0.8          0.65                      0.4   \n",
       "7                     0.8          0.40                      0.4   \n",
       "8                     1.0          0.00                      0.2   \n",
       "9                     0.9          0.75                      0.4   \n",
       "\n",
       "                                                                                question  \\\n",
       "0                                                            how can I make topic model?   \n",
       "1                                               how much data is needed for topic model?   \n",
       "2                                                     can LLMs be used for topic models?   \n",
       "3                                           what are the steps for training topic model?   \n",
       "4                                      What kind of analysis can I make in the platform?   \n",
       "5                                                            how to find unwanted calls?   \n",
       "6                          what are options for sentiment detection in call transcripts?   \n",
       "7                  where should I start if I am total beginner in using the application?   \n",
       "8                                                   can I download data into excel file?   \n",
       "9  anonymization is not working correctly, some names are not removed. What should I do?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                answer  \n",
       "0  assistant: To create a topic model using the FS Text application, you can follow these steps:\\n\\n1. Log in to the FS Text application and choose the Model builder menu item.\\n2. In the Model builder view, click on the New model option in the left-hand menu.\\n3. Fill in the form for your new model with a descriptive name, description, business purpose, and language. Choose Topic model as your Model type and press Create model.\\n4. Upload your data using an Excel file in the Model and data view. Ensure all data is included in one Excel file.\\n5. Review the data to validate if it was uploaded correctly in the Review data view.\\n6. Add words to be removed in the Cleaners tab, such as stopwords, in a specific format.\\n7. Clean the data in the Clean data area, which involves processes like lowercasing text, removing punctuation, and lemmatization.\\n8. Generate ngrams in the Ngrams tab to grasp common terms in the text.\\n9. Start the model training process by providing the number of topics and clicking on the Train model button in the Train model view.\\n10. Review the training experiments and adjust the number of topics if needed in the Experiments view.\\n11. Test the trained model by writing/copying a text in the Predict view.\\n12. Finish up by iterating through cleaning and training rounds, ensuring the topics make sense and experimenting with different numbers of topics until you achieve informative results.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      assistant: The data needed for creating a topic model can vary, but typically a few hundred to a few thousand texts are required as input data.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               assistant: LLMs (Large Language Models) are not directly mentioned in the context of creating topic models. If you need more specific information on how LLMs can be used for topic models, please provide additional details or context for a more accurate response.  \n",
       "3                                                                                                                                                                                               assistant: Training a topic model involves several steps. Here is an overview of the process:\\n\\n1. Log in to the FS Text application and access the Model builder menu.\\n2. Create a new model by providing details like name, description, business purpose, and language.\\n3. Choose \"Topic model\" as the Model type and create the model.\\n4. Upload data in the Model and data view using an Excel file.\\n5. Review the data in the Review data view to validate the correct format and content.\\n6. Clean the data by removing stopwords and other unnecessary words in the Cleaners tab.\\n7. Generate ngrams for common terms in the text in the Ngrams tab.\\n8. Train the model by specifying the number of topics and initiating the training process in the Train model view.\\n9. Monitor the training progress in the Logs under Training logs.\\n10. Review the results in the Experiments view to evaluate topics, adjust as needed, and name them accordingly.\\n11. Test the trained model in the Predict view by inputting text to predict its topic.\\n\\nThe training process may involve multiple rounds of cleaning and training to refine the model for accurate topic classification. It is crucial to ensure that the topics generated make sense and are distinct.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    assistant: You can conduct various types of analysis on the platform, including real-time conversation analysis, short-term monitoring and evaluation, medium-term trend tracking, long-term performance reviews, competitor analysis, customer satisfaction trend analysis, product/service feedback analysis, conversation topic analysis, seasonal trend identification, customer lifecycle analysis, long-term strategy development, customer loyalty analysis, predictive analytics, and reclamation and complaint handling.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                         assistant: To find unwanted calls, you can follow these steps:\\n\\n1. **Check Call Logs**: Review your call logs to identify numbers that you don't recognize or have a history of unwanted calls.\\n\\n2. **Use Call Blocking Apps**: Install call blocking apps on your phone that can automatically detect and block spam calls.\\n\\n3. **Register with Do Not Call Registry**: Register your phone number with the national \"Do Not Call\" registry to reduce telemarketing calls.\\n\\n4. **Report Unwanted Calls**: Report unwanted calls to your phone carrier or the Federal Trade Commission (FTC) to help track and stop spam callers.\\n\\n5. **Avoid Answering Unknown Numbers**: If you receive a call from an unknown number, avoid answering it to prevent unwanted calls.\\n\\n6. **Enable Call Screening**: Use call screening features on your phone to filter out unwanted calls based on pre-defined criteria.\\n\\nBy following these steps, you can effectively identify and reduce unwanted calls.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               assistant: The options for sentiment detection in call transcripts include using supervised AI models that are accurate but require human labeling, and unsupervised AI models that do not need human labeling but may be harder to interpret. Supervised models are guided and accurate, while unsupervised models can identify patterns that may not have been initially considered.  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      assistant: If you are a total beginner in using the application, you should start by understanding the data available, creating an overview, setting goals or questions, validating and measuring hypotheses, and monitoring changes over time. This step-by-step guide will help you get started with analyzing customer feedback effectively.  \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           assistant: To assist you with downloading data into an Excel file, I will first need to understand the context or source of the data you are referring to. Could you please provide more details about the data source or the specific data you would like to download into an Excel file?  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 assistant: To address the issue where some names are not being removed during anonymization, you should first review the anonymization settings in the Leadstream application. Check if the names that are not being removed are configured correctly in the anonymization rules. Ensure that the names are included in the list of PII (Personally Identifiable Information) that should be anonymized. If the issue persists, consider reaching out to your Customer Success Manager for further assistance in adjusting the anonymization settings to ensure all sensitive information, including names, is properly masked in the conversations.  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[['answer_relevance_score','ground_score', 'context_relevance_score', 'question','answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02f58066",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RistoHinno\\AppData\\Local\\Temp\\ipykernel_10584\\3876928364.py:1: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df_results[['answer_relevance_score','ground_score', 'context_relevance_score', 'question','answer']].to_excel('rag_agent.xlsx')\n"
     ]
    }
   ],
   "source": [
    "df_results[['answer_relevance_score','ground_score', 'context_relevance_score', 'question','answer']].to_excel('rag_agent.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1924ecf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## try to correct the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67626912",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#take answer that has low groundedness\n",
    "prompt=\"I asked a question 'can LLMs be used for topic models?' and you gave this answer which was not gorunded based on the documents. please give correct answer which is based only on documents and not on previous knowledge. if documents don't mention this topic, say so. Old answer: 'LLMs (Large Language Models) can be used for topic modeling tasks. These models, like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), have been applied to various natural language processing tasks, including topic modeling. LLMs can be fine-tuned on specific datasets to perform topic modeling tasks effectively. By leveraging the contextual understanding and representation capabilities of LLMs, researchers and practitioners can create topic models that capture the underlying themes and topics present in a corpus of text data.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9966ea1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step a71f405f-f481-4b82-b8f3-481e57c8f4a2. Step input: I asked a question 'can LLMs be used for topic models?' and you gave this answer which was not gorunded based on the documents. please give correct answer which is based only on documents and not on previous knowledge. if documents don't mention this topic, say so. Old answer: 'LLMs (Large Language Models) can be used for topic modeling tasks. These models, like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), have been applied to various natural language processing tasks, including topic modeling. LLMs can be fine-tuned on specific datasets to perform topic modeling tasks effectively. By leveraging the contextual understanding and representation capabilities of LLMs, researchers and practitioners can create topic models that capture the underlying themes and topics present in a corpus of text data.'\n",
      "Added user message to memory: I asked a question 'can LLMs be used for topic models?' and you gave this answer which was not gorunded based on the documents. please give correct answer which is based only on documents and not on previous knowledge. if documents don't mention this topic, say so. Old answer: 'LLMs (Large Language Models) can be used for topic modeling tasks. These models, like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), have been applied to various natural language processing tasks, including topic modeling. LLMs can be fine-tuned on specific datasets to perform topic modeling tasks effectively. By leveraging the contextual understanding and representation capabilities of LLMs, researchers and practitioners can create topic models that capture the underlying themes and topics present in a corpus of text data.'\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_How_to_create_a_topic_model with args: {\"input\": \"can LLMs be used for topic models?\"}\n",
      "=== Function Output ===\n",
      "Yes, LLMs can be used for topic models.\n",
      "> Running step a0909b67-39c8-4a1d-91b4-3ffb7f51b86b. Step input: None\n",
      "=== LLM Response ===\n",
      "The documents do not provide specific information on whether LLMs can be used for topic models.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4035a7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}