{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6-q-gTUaZU7",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Lesson 2: RAG Triad of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 47,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 98,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "‚úÖ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RistoHinno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 81,
    "id": "IBfdyn3MaZU9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## laod data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def list_files_recursively(directory):\n",
    "    paths=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "    return paths\n",
    "\n",
    "# Example usage\n",
    "papers=list_files_recursively('support_articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 98,
    "id": "wMvq1q8yaZU-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "#     input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    "    input_files=papers\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 81,
    "id": "sY8Oui4taZU-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 217,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "# from llama_index.llms import OpenAI\n",
    "from  llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1, api_key=openai.api_key)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "#     embed_model='text-embedding-ada-002',\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 81,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = \\\n",
    "get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 64,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Texts as input and no labelling are needed to create a topic model.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sentence_window_engine.query(\n",
    "    \"What is needed to create topic model?\")\n",
    "output.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 64,
    "id": "5KqV-IbQaZVB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 64,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import OpenAI as fOpenAI\n",
    "\n",
    "provider = fOpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "height": 115,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback\n",
    "\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "height": 64,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "\n",
    "context_selection = TruLlama.select_source_nodes().node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "height": 166,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "height": 166,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance_with_cot_reasons,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Groundedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "height": 64,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RistoHinno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 149,
    "id": "kXJBD4gfaZVC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons,\n",
    "             name=\"Groundedness\"\n",
    "            )\n",
    "    .on(context_selection)\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation of the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "height": 217,
    "id": "KUDHInR-aZVC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "from trulens_eval import FeedbackMode\n",
    "\n",
    "tru_recorder = TruLlama(\n",
    "    sentence_window_engine,\n",
    "    app_id=\"App_1\",\n",
    "    feedbacks=[\n",
    "        f_qa_relevance,\n",
    "        f_qs_relevance,\n",
    "        f_groundedness\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "height": 115,
    "id": "dsA3ziw1aZVD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('data/eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "height": 30,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how can I make topic model?',\n",
       " 'how much data is needed for topic model?',\n",
       " 'can LLMs be used for topic models?',\n",
       " 'what are the steps for training topic model?',\n",
       " 'What kind of analysis can I make in the platform?',\n",
       " 'how to find unwanted calls?',\n",
       " 'what are options for sentiment detection in call transcripts?',\n",
       " 'where should I start if I am total beginner in using the application?',\n",
       " 'can I download data into excel file?',\n",
       " 'anonymization is not working correctly, some names are not removed. What should I do?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "height": 64,
    "id": "01_P6TxaaZVD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a289885a4a3044d9a6b89d8913f0ec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffee11e03584dafae83742095926588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c88ce9cfb3e4305af2ac5089234c811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9ab3490ff54305b5c0148f4e138ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b50968dfdf409abe5f50657ff490dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e841c5de8a82426280236a2b586ff8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4706c0a16e5427ea1d9ede59f1b513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92c7b2501744396a7cbee93efdfb6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f478c54f8034b4f8d934bd77eb0b805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368c48ebd7a84a849deb3d0d68a9b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7dedf247bb49979872e45572553235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e7615c29bf404ebdd42e3a0f06de7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26caad918d1c41fdbb5203eea148e1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6630f6a011af4deca6a67e96daa02c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6b575c591b427a8fb623fc2b860108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e866467b35d4c639581feb7c77724da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        sentence_window_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "height": 47,
    "id": "sNPhDde6ZArq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>App_1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_68a5a07d88c9d889c1e9d62bfe1fdafa</td>\n",
       "      <td>\"how can I make topic model?\"</td>\n",
       "      <td>\"To create a topic model, log in to the FS Tex...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_68a5a07d88c9d889c1e...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-05-14T09:31:12.040127\", \"...</td>\n",
       "      <td>2024-05-14T09:31:16.417120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'how can I make topic mod...</td>\n",
       "      <td>[{'args': {'question': 'how can I make topic m...</td>\n",
       "      <td>[{'args': {'source': 'Model creation form\n",
       "\n",
       "Now...</td>\n",
       "      <td>4</td>\n",
       "      <td>563</td>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>App_1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_18f471fc1b797765e626e795c71c09c1</td>\n",
       "      <td>\"how much data is needed for topic model?\"</td>\n",
       "      <td>\"The more data you have, the longer the traini...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_18f471fc1b797765e62...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-05-14T09:31:16.796523\", \"...</td>\n",
       "      <td>2024-05-14T09:31:20.074531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'how much data is needed ...</td>\n",
       "      <td>[{'args': {'question': 'how much data is neede...</td>\n",
       "      <td>[{'args': {'source': 'You have to provide the ...</td>\n",
       "      <td>3</td>\n",
       "      <td>441</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>App_1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_e934efd789a0bd6e47b6b3856c102f4d</td>\n",
       "      <td>\"can LLMs be used for topic models?\"</td>\n",
       "      <td>\"LLMs can be used for topic models.\"</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_e934efd789a0bd6e47b...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-05-14T09:31:20.432088\", \"...</td>\n",
       "      <td>2024-05-14T09:31:23.709058</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'can LLMs be used for top...</td>\n",
       "      <td>[{'args': {'question': 'can LLMs be used for t...</td>\n",
       "      <td>[{'args': {'source': 'Model creation form\n",
       "\n",
       "Now...</td>\n",
       "      <td>3</td>\n",
       "      <td>391</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>App_1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_b46b33c7c6c3a4fd583b0ba70c713713</td>\n",
       "      <td>\"what are the steps for training topic model?\"</td>\n",
       "      <td>\"To train a topic model using the FS Text appl...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_b46b33c7c6c3a4fd583...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-05-14T09:31:24.001187\", \"...</td>\n",
       "      <td>2024-05-14T09:31:28.216402</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'what are the steps for t...</td>\n",
       "      <td>[{'args': {'question': 'what are the steps for...</td>\n",
       "      <td>[{'args': {'source': 'The main topic/area:\n",
       "\n",
       "\n",
       "\n",
       "...</td>\n",
       "      <td>4</td>\n",
       "      <td>610</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App_1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_1a1e43c360341e65ac0aefd7d6f07cc6</td>\n",
       "      <td>\"What kind of analysis can I make in the platf...</td>\n",
       "      <td>\"You can conduct topic prediction analysis on ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_1a1e43c360341e65ac0...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-05-14T09:31:28.691255\", \"...</td>\n",
       "      <td>2024-05-14T09:31:31.661930</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[{'args': {'prompt': 'What kind of analysis ca...</td>\n",
       "      <td>[{'args': {'question': 'What kind of analysis ...</td>\n",
       "      <td>[{'args': {'source': 'Predict\n",
       "\n",
       "‚ÄúPredict‚Äù.  Thi...</td>\n",
       "      <td>2</td>\n",
       "      <td>329</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  app_id                                           app_json  \\\n",
       "0  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_68a5a07d88c9d889c1e9d62bfe1fdafa   \n",
       "1  record_hash_18f471fc1b797765e626e795c71c09c1   \n",
       "2  record_hash_e934efd789a0bd6e47b6b3856c102f4d   \n",
       "3  record_hash_b46b33c7c6c3a4fd583b0ba70c713713   \n",
       "4  record_hash_1a1e43c360341e65ac0aefd7d6f07cc6   \n",
       "\n",
       "                                               input  \\\n",
       "0                      \"how can I make topic model?\"   \n",
       "1         \"how much data is needed for topic model?\"   \n",
       "2               \"can LLMs be used for topic models?\"   \n",
       "3     \"what are the steps for training topic model?\"   \n",
       "4  \"What kind of analysis can I make in the platf...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"To create a topic model, log in to the FS Tex...    -   \n",
       "1  \"The more data you have, the longer the traini...    -   \n",
       "2               \"LLMs can be used for topic models.\"    -   \n",
       "3  \"To train a topic model using the FS Text appl...    -   \n",
       "4  \"You can conduct topic prediction analysis on ...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_68a5a07d88c9d889c1e...   \n",
       "1  {\"record_id\": \"record_hash_18f471fc1b797765e62...   \n",
       "2  {\"record_id\": \"record_hash_e934efd789a0bd6e47b...   \n",
       "3  {\"record_id\": \"record_hash_b46b33c7c6c3a4fd583...   \n",
       "4  {\"record_id\": \"record_hash_1a1e43c360341e65ac0...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-05-14T09:31:12.040127\", \"...   \n",
       "1  {\"start_time\": \"2024-05-14T09:31:16.796523\", \"...   \n",
       "2  {\"start_time\": \"2024-05-14T09:31:20.432088\", \"...   \n",
       "3  {\"start_time\": \"2024-05-14T09:31:24.001187\", \"...   \n",
       "4  {\"start_time\": \"2024-05-14T09:31:28.691255\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-05-14T09:31:16.417120               1.0                0.5   \n",
       "1  2024-05-14T09:31:20.074531               0.2                0.8   \n",
       "2  2024-05-14T09:31:23.709058               0.2                0.2   \n",
       "3  2024-05-14T09:31:28.216402               0.8                0.7   \n",
       "4  2024-05-14T09:31:31.661930               0.8                0.8   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           1.0  [{'args': {'prompt': 'how can I make topic mod...   \n",
       "1           1.0  [{'args': {'prompt': 'how much data is needed ...   \n",
       "2           0.0  [{'args': {'prompt': 'can LLMs be used for top...   \n",
       "3           1.0  [{'args': {'prompt': 'what are the steps for t...   \n",
       "4           0.7  [{'args': {'prompt': 'What kind of analysis ca...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'question': 'how can I make topic m...   \n",
       "1  [{'args': {'question': 'how much data is neede...   \n",
       "2  [{'args': {'question': 'can LLMs be used for t...   \n",
       "3  [{'args': {'question': 'what are the steps for...   \n",
       "4  [{'args': {'question': 'What kind of analysis ...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'Model creation form\n",
       "\n",
       "Now...        4           563   \n",
       "1  [{'args': {'source': 'You have to provide the ...        3           441   \n",
       "2  [{'args': {'source': 'Model creation form\n",
       "\n",
       "Now...        3           391   \n",
       "3  [{'args': {'source': 'The main topic/area:\n",
       "\n",
       "\n",
       "\n",
       "...        4           610   \n",
       "4  [{'args': {'source': 'Predict\n",
       "\n",
       "‚ÄúPredict‚Äù.  Thi...        2           329   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000888  \n",
       "1    0.000673  \n",
       "2    0.000591  \n",
       "3    0.000942  \n",
       "4    0.000499  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "height": 81,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"how can I make topic model?\"</td>\n",
       "      <td>\"To create a topic model, log in to the FS Text application and choose the Model builder menu item. In the Model builder view, click on the New model option in the left-hand menu. Fill in the form with a descriptive name, description, business purpose, and language. Choose Topic model as the Model type from the dropdown menu and then press Create model. Follow the model creation steps as listed in tabs after creating the model.\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"how much data is needed for topic model?\"</td>\n",
       "      <td>\"The more data you have, the longer the training process duration will be, usually not longer than a few minutes.\"</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"can LLMs be used for topic models?\"</td>\n",
       "      <td>\"LLMs can be used for topic models.\"</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"what are the steps for training topic model?\"</td>\n",
       "      <td>\"To train a topic model using the FS Text application, follow these steps:\\n\\n1. Log in to the FS Text application.\\n2. Choose the Model builder menu item.\\n3. In the Model builder view, click on the New model option in the left-hand menu.\"</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"What kind of analysis can I make in the platform?\"</td>\n",
       "      <td>\"You can conduct topic prediction analysis on the platform.\"</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"how to find unwanted calls?\"</td>\n",
       "      <td>\"To find unwanted calls, you can utilize a Topic model in the Model builder view. By analyzing the topics generated in the bubble chart, you can identify topics related to unwanted calls based on the words associated with each topic. Look for topics that contain keywords or phrases commonly associated with unwanted calls, such as spam, telemarketing, or nuisance. If you encounter topics that do not align with identifying unwanted calls, you may need to adjust the cleaning pipeline by removing more words or consider changing the number of topics to better capture the relevant information.\"</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"what are options for sentiment detection in call transcripts?\"</td>\n",
       "      <td>\"The options for sentiment detection in call transcripts include using sentiment analysis models that can analyze the text data to determine the sentiment expressed in the conversations. These models can classify the sentiment as positive, negative, or neutral based on the language used in the call transcripts.\"</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"where should I start if I am total beginner in using the application?\"</td>\n",
       "      <td>\"Start by logging into the FS Text application and selecting the Model builder menu item.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"can I download data into excel file?\"</td>\n",
       "      <td>\"Yes, you can download data into an Excel file.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"anonymization is not working correctly, some names are not removed. What should I do?\"</td>\n",
       "      <td>\"You should review the list of words that are meant to be removed during the anonymization process. Check if the names that are not being removed are included in the list of words to be removed. If they are not, consider adding those specific names to the list in the correct format and save the updated list. This should help improve the anonymization process by ensuring that the names you want to remove are included in the removal list.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     input  \\\n",
       "0                                                            \"how can I make topic model?\"   \n",
       "1                                               \"how much data is needed for topic model?\"   \n",
       "2                                                     \"can LLMs be used for topic models?\"   \n",
       "3                                           \"what are the steps for training topic model?\"   \n",
       "4                                      \"What kind of analysis can I make in the platform?\"   \n",
       "5                                                            \"how to find unwanted calls?\"   \n",
       "6                          \"what are options for sentiment detection in call transcripts?\"   \n",
       "7                  \"where should I start if I am total beginner in using the application?\"   \n",
       "8                                                   \"can I download data into excel file?\"   \n",
       "9  \"anonymization is not working correctly, some names are not removed. What should I do?\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                output  \\\n",
       "0                                                                                                                                                                     \"To create a topic model, log in to the FS Text application and choose the Model builder menu item. In the Model builder view, click on the New model option in the left-hand menu. Fill in the form with a descriptive name, description, business purpose, and language. Choose Topic model as the Model type from the dropdown menu and then press Create model. Follow the model creation steps as listed in tabs after creating the model.\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \"The more data you have, the longer the training process duration will be, usually not longer than a few minutes.\"   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"LLMs can be used for topic models.\"   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                     \"To train a topic model using the FS Text application, follow these steps:\\n\\n1. Log in to the FS Text application.\\n2. Choose the Model builder menu item.\\n3. In the Model builder view, click on the New model option in the left-hand menu.\"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \"You can conduct topic prediction analysis on the platform.\"   \n",
       "5  \"To find unwanted calls, you can utilize a Topic model in the Model builder view. By analyzing the topics generated in the bubble chart, you can identify topics related to unwanted calls based on the words associated with each topic. Look for topics that contain keywords or phrases commonly associated with unwanted calls, such as spam, telemarketing, or nuisance. If you encounter topics that do not align with identifying unwanted calls, you may need to adjust the cleaning pipeline by removing more words or consider changing the number of topics to better capture the relevant information.\"   \n",
       "6                                                                                                                                                                                                                                                                                            \"The options for sentiment detection in call transcripts include using sentiment analysis models that can analyze the text data to determine the sentiment expressed in the conversations. These models can classify the sentiment as positive, negative, or neutral based on the language used in the call transcripts.\"   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \"Start by logging into the FS Text application and selecting the Model builder menu item.\"   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \"Yes, you can download data into an Excel file.\"   \n",
       "9                                                                                                                                                            \"You should review the list of words that are meant to be removed during the anonymization process. Check if the names that are not being removed are included in the list of words to be removed. If they are not, consider adding those specific names to the list in the correct format and save the updated list. This should help improve the anonymization process by ensuring that the names you want to remove are included in the removal list.\"   \n",
       "\n",
       "   Answer Relevance  Context Relevance  Groundedness  \n",
       "0               1.0                0.5           1.0  \n",
       "1               0.2                0.8           1.0  \n",
       "2               0.2                0.2           0.0  \n",
       "3               0.8                0.7           1.0  \n",
       "4               0.8                0.8           0.7  \n",
       "5               0.8                0.3           NaN  \n",
       "6               0.8                0.2           0.0  \n",
       "7               NaN                NaN           NaN  \n",
       "8               NaN                NaN           NaN  \n",
       "9               NaN                NaN           NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "height": 30,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d70b9725de477cb126df20872b0316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>App_1</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Answer Relevance  Context Relevance  Groundedness  latency  total_cost\n",
       "app_id                                                                        \n",
       "App_1           0.657143                0.5      0.616667      3.4    0.000723"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "height": 30,
    "id": "6Yp4_e4faZVD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9574f3243bc54083b7b55092d2a89224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://10.8.0.8:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8590efd7f8bd4f849c682536ac1e0058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0e46803e37430ab06c79f6116a4853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dd01ffa93a40aab0d6c814e712fdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ChKW1kEIUcUVDDTWjpA5Tf_ib3Hhp3uS",
     "timestamp": 1695164681916
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}