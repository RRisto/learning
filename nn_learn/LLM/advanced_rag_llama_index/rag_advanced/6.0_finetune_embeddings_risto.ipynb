{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568dc405-835d-4151-9719-f131eb303923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install weaviate-client\n",
    "# !pip install llama_index==0.9.14\n",
    "# !pip install llama_index==0.9.24\n",
    "# !pip install openai\n",
    "# !pip install --upgrade pydantic==1.10.12 typing-extensions==4.5.0\n",
    "# !pip install fastcore\n",
    "# !pip install typing-extensions==4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec86ce8-2b49-4a85-9289-8fb7accab63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_231/3209183068.py:15: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth',-1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from llama_index.finetuning import (\n",
    "    generate_qa_embedding_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.llms import OpenAI as OpenAILLama\n",
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "\n",
    "pd.set_option('display.max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bf25a-97f0-466c-a481-67c8e01303b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f18d21-dd53-4742-a34c-d02c67085896",
   "metadata": {},
   "source": [
    "## Load conf, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadc832c-3a33-4637-a092-89688f0b567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=ConfigParser()\n",
    "config.read('conf/conf.ini')\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai']['apikey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3162f4-d71a-4e28-a5d7-c014308826a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILLama(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d89489-32dc-4c20-96f1-3dae4a1a538a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bcc23-0130-4eca-974d-68a6371c910b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6741e0-bf5f-47be-934a-b39a62b57745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410335, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('data/riigikogu_w_meta/data_all.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0787f433-4c87-498e-8537-63e6d804f498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>speaker</th>\n",
       "      <th>index_pk</th>\n",
       "      <th>index_snd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>ntoks_splitted</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_prob</th>\n",
       "      <th>Name</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>cluster_name_very_high</th>\n",
       "      <th>topic_reduce_outliers</th>\n",
       "      <th>Name_red_outliers</th>\n",
       "      <th>fation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15:00  Istungi rakendamine</td>\n",
       "      <td>Esimees Ene Ergma</td>\n",
       "      <td>PKP-18479</td>\n",
       "      <td>SND-439218</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15:00</td>\n",
       "      <td>tere päevast lugupeetud riigikogu ilusat jätkuvat aastat teile kõigile alustame riigikogu täiskogu vii istungjärgu esimese töönädala esmaspäevast istungit</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>154548</td>\n",
       "      <td>574</td>\n",
       "      <td>0.402741</td>\n",
       "      <td>574_töönädala_istungjärgu_istungit_alustame</td>\n",
       "      <td>istungjärgu_töönädala_arupärimisi_istungit_tere</td>\n",
       "      <td>palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove</td>\n",
       "      <td>574</td>\n",
       "      <td>574_töönädala_istungjärgu_istungit_alustame</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.\\n                        15:01  Riigikogu liikme Katrin Karisma-Krummi ametivanne</td>\n",
       "      <td>Esimees Ene Ergma</td>\n",
       "      <td>PKP-18480</td>\n",
       "      <td>SND-439219</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15:01</td>\n",
       "      <td>head kolleegid palun tähelepanu seoses riigikogu liikme ülle rajasalu volituste lõppemisega tema nimetamise tõttu harju maavanemaks asus alates eelmise aasta 21. detsembrist riigikogu liikmeks asendusliige katrin karisma-krumm lugupeetud riigikogu meil on nüüd meeldiv võimalus ära kuulata riigikogu liikme katrin karisma-krummi ametivanne palun</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>154549</td>\n",
       "      <td>448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>448_ametivande_ametivanne_liikmeks_tagasiastumisega</td>\n",
       "      <td>ametivande_ametivanne_kuulame_liikmeks_tagasiastumisega</td>\n",
       "      <td>aastal_eurot_euroopa_aasta_kui</td>\n",
       "      <td>448</td>\n",
       "      <td>448_ametivande_ametivanne_liikmeks_tagasiastumisega</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.\\n                        15:01  Riigikogu liikme Katrin Karisma-Krummi ametivanne</td>\n",
       "      <td>Katrin Karisma-Krumm</td>\n",
       "      <td>PKP-18480</td>\n",
       "      <td>SND-439220</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15:01</td>\n",
       "      <td>asudes täitma oma kohustusi riigikogu liikmena riigikogu xi koosseisus annan vande jääda ustavaks eesti vabariigile ja tema põhiseaduslikule korrale aplaus</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>154550</td>\n",
       "      <td>1343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1343_ustavaks_vande_vabariigile_asudes</td>\n",
       "      <td>ustavaks_põhiseaduslikule_asudes_vabariigile_korrale</td>\n",
       "      <td>palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove</td>\n",
       "      <td>1343</td>\n",
       "      <td>1343_ustavaks_vande_vabariigile_asudes</td>\n",
       "      <td>Eesti Reformierakonna fraktsioon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15:02  Istungi rakendamine</td>\n",
       "      <td>Esimees Ene Ergma</td>\n",
       "      <td>PKP-18481</td>\n",
       "      <td>SND-439223</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15:02</td>\n",
       "      <td>aitäh palun kolleeg mailis reps</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>154555</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1_ma_te_me_et</td>\n",
       "      <td>-1_ma_te_me_et</td>\n",
       "      <td>-1_ma_te_me_et</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262_reps_mailis_teine_küsimus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15:02  Istungi rakendamine</td>\n",
       "      <td>Esimees Ene Ergma</td>\n",
       "      <td>PKP-18481</td>\n",
       "      <td>SND-439225</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15:02</td>\n",
       "      <td>aitäh palun kolleeg eiki nestor</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>154558</td>\n",
       "      <td>331</td>\n",
       "      <td>0.874070</td>\n",
       "      <td>331_nestor_eiki_küsimuseks_protseduuriline</td>\n",
       "      <td>nestor_eiki_kolleeg_palun_küsimuseks</td>\n",
       "      <td>palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove</td>\n",
       "      <td>331</td>\n",
       "      <td>331_nestor_eiki_küsimuseks_protseduuriline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                heading  \\\n",
       "0  15:00  Istungi rakendamine                                                             \n",
       "1  1.\\n                        15:01  Riigikogu liikme Katrin Karisma-Krummi ametivanne   \n",
       "2  1.\\n                        15:01  Riigikogu liikme Katrin Karisma-Krummi ametivanne   \n",
       "3  15:02  Istungi rakendamine                                                             \n",
       "4  15:02  Istungi rakendamine                                                             \n",
       "\n",
       "                speaker   index_pk   index_snd  year  month  day   time  \\\n",
       "0  Esimees Ene Ergma     PKP-18479  SND-439218  2010  1      11   15:00   \n",
       "1  Esimees Ene Ergma     PKP-18480  SND-439219  2010  1      11   15:01   \n",
       "2  Katrin Karisma-Krumm  PKP-18480  SND-439220  2010  1      11   15:01   \n",
       "3  Esimees Ene Ergma     PKP-18481  SND-439223  2010  1      11   15:02   \n",
       "4  Esimees Ene Ergma     PKP-18481  SND-439225  2010  1      11   15:02   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                               text_wo_punct  \\\n",
       "0  tere päevast lugupeetud riigikogu ilusat jätkuvat aastat teile kõigile alustame riigikogu täiskogu vii istungjärgu esimese töönädala esmaspäevast istungit                                                                                                                                                                                                  \n",
       "1  head kolleegid palun tähelepanu seoses riigikogu liikme ülle rajasalu volituste lõppemisega tema nimetamise tõttu harju maavanemaks asus alates eelmise aasta 21. detsembrist riigikogu liikmeks asendusliige katrin karisma-krumm lugupeetud riigikogu meil on nüüd meeldiv võimalus ära kuulata riigikogu liikme katrin karisma-krummi ametivanne palun   \n",
       "2  asudes täitma oma kohustusi riigikogu liikmena riigikogu xi koosseisus annan vande jääda ustavaks eesti vabariigile ja tema põhiseaduslikule korrale aplaus                                                                                                                                                                                                 \n",
       "3  aitäh palun kolleeg mailis reps                                                                                                                                                                                                                                                                                                                             \n",
       "4  aitäh palun kolleeg eiki nestor                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "         date  ... ntoks_splitted  doc_id topic_id  topic_prob  \\\n",
       "0  2010-01-11  ...  18             154548  574      0.402741     \n",
       "1  2010-01-11  ...  42             154549  448      1.000000     \n",
       "2  2010-01-11  ...  20             154550  1343     1.000000     \n",
       "3  2010-01-11  ...  5              154555 -1        0.000000     \n",
       "4  2010-01-11  ...  5              154558  331      0.874070     \n",
       "\n",
       "                                                  Name  \\\n",
       "0  574_töönädala_istungjärgu_istungit_alustame           \n",
       "1  448_ametivande_ametivanne_liikmeks_tagasiastumisega   \n",
       "2  1343_ustavaks_vande_vabariigile_asudes                \n",
       "3  -1_ma_te_me_et                                        \n",
       "4  331_nestor_eiki_küsimuseks_protseduuriline            \n",
       "\n",
       "                                              cluster_name  \\\n",
       "0  istungjärgu_töönädala_arupärimisi_istungit_tere           \n",
       "1  ametivande_ametivanne_kuulame_liikmeks_tagasiastumisega   \n",
       "2  ustavaks_põhiseaduslikule_asudes_vabariigile_korrale      \n",
       "3  -1_ma_te_me_et                                            \n",
       "4  nestor_eiki_kolleeg_palun_küsimuseks                      \n",
       "\n",
       "                                   cluster_name_very_high  \\\n",
       "0  palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove   \n",
       "1  aastal_eurot_euroopa_aasta_kui                           \n",
       "2  palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove   \n",
       "3  -1_ma_te_me_et                                           \n",
       "4  palun_lugemine_juhtivkomisjoni_läbirääkimisi_kõnesoove   \n",
       "\n",
       "  topic_reduce_outliers                                    Name_red_outliers  \\\n",
       "0  574                   574_töönädala_istungjärgu_istungit_alustame           \n",
       "1  448                   448_ametivande_ametivanne_liikmeks_tagasiastumisega   \n",
       "2  1343                  1343_ustavaks_vande_vabariigile_asudes                \n",
       "3  1262                  1262_reps_mailis_teine_küsimus                        \n",
       "4  331                   331_nestor_eiki_küsimuseks_protseduuriline            \n",
       "\n",
       "                             fation  \n",
       "0  NaN                               \n",
       "1  NaN                               \n",
       "2  Eesti Reformierakonna fraktsioon  \n",
       "3  NaN                               \n",
       "4  NaN                               \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7ba76a-1442-4bd0-b1c2-e71f7e2a6a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022    50569\n",
       "2016    34844\n",
       "2017    34692\n",
       "2021    34099\n",
       "2020    33611\n",
       "2010    31222\n",
       "2018    29045\n",
       "2014    27792\n",
       "2012    25102\n",
       "2023    25000\n",
       "2015    24340\n",
       "2011    21893\n",
       "2019    21078\n",
       "2013    17048\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c53aea-f477-488c-8460-2bde7263b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410335,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_ar=np.load('data/riigikogu_w_meta/embs_all.npy', allow_pickle=True)\n",
    "embs_ar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969eacf-ead0-4324-a9fb-8e20dd3195e1",
   "metadata": {},
   "source": [
    "## Let's keep meaningful topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c383dfbb-912b-4253-9600-2fe0bde33482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2107, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_info=pd.read_excel('data/riigikogu_w_meta/topics_info2022_manual_review.xlsx')\n",
    "df_topic_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe11bb4d-d1f1-406d-a332-ebc00abad59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meaningful_topics=df_topic_info[df_topic_info.manual_cluster=='sisukas'].Name.tolist()\n",
    "len(meaningful_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ad4fdd7-b583-4661-9b9f-055c19376241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96704, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Name_red_outliers=='-1_ma_te_me_et'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ce0ac8-d706-4b15-92ef-5efa3722b3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95108, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Name_red_outliers=='-1_ma_te_me_et')&(df.ntoks_splitted>6)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b0cca-6c94-4686-9d66-e4fe7444285b",
   "metadata": {},
   "source": [
    "## Let's use year 2023 as test year and 2022 as train year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95855f51-9de7-4112-9137-f75dd0959cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95108, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=df[df.Name_red_outliers.isin(meaningful_topics)]\n",
    "df=df[df.Name_red_outliers.isin(['-1_ma_te_me_et'])&(df.ntoks_splitted>6)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9d34d9-20c4-45f9-920b-6cba612d3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95106, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove duplicated text\n",
    "df=df[~df.text_splitted.duplicated()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed6ba25-4828-41fe-9034-77ddd63f9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.year==2023].Name_red_outliers.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a32b97f-3f4d-4f2b-a3ad-bba82d479d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.year==2022].Name_red_outliers.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "543150a3-c67e-4dae-95d2-3575ec746f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 300, (2000,), (300,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx_train=df[(df.year==2022)].sample(1000, random_state=43).index\n",
    "# idx_val=df[(df.year==2023)].sample(300, random_state=43).index\n",
    "\n",
    "idx_train=df.sample(1000, random_state=43).index\n",
    "idx_val=df[~df.index.isin(idx_train)].sample(300, random_state=43).index\n",
    "\n",
    "texts_train=df.loc[idx_train.tolist()].text_splitted.tolist()\n",
    "texts_val=df.loc[idx_val.tolist()].text_splitted.tolist()\n",
    "embs_train=embs_ar[idx_train]\n",
    "embs_val=embs_ar[idx_val]\n",
    "\n",
    "len(texts_train), len(texts_val), embs_train.shape, embs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "753fc00d-766b-40de-a4d7-06d8e4f068ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(idx_train)&set(idx_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887c2c0-04f9-4d53-a2b0-f728b8bc65ec",
   "metadata": {},
   "source": [
    "## Create nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bce68f5-e264-4ae3-b5d7-e99ccbbc16d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_nodes(texts, embs_ar):\n",
    "    nodes = []\n",
    "    for idx, sample in enumerate(texts):\n",
    "        metadata=dict()\n",
    "        node = TextNode(\n",
    "            text=sample,\n",
    "        )\n",
    "        node.embedding=embs_ar[idx]\n",
    "        \n",
    "        nodes.append(node)\n",
    "    return nodes\n",
    "\n",
    "nodes_train=create_nodes(texts_train, embs_train)\n",
    "nodes_val=create_nodes(texts_val, embs_val)\n",
    "len(nodes_train), len(nodes_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddd42e-0930-40a6-a872-6c3dde183b4d",
   "metadata": {},
   "source": [
    "## Generate synthetic queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7673748e-92fc-4857-bfef-fbd0cf80c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generate_prompt_tmpl = 'Context information is below.\\n\\n---------------------\\n{context_str}\\n---------------------\\n\\nGiven the context information and not prior knowledge.\\ngenerate only questions based on the below query.\\n\\nYou are a Teacher/ Professor. Your task is to setup {num_questions_per_chunk} questions for an upcoming quiz/examination. The questions should be diverse in nature across the document. Restrict the questions to the context information provided. Please create questions only in Estonian.\"\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b789001a-da87-432a-9b1e-76629cab1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = generate_qa_embedding_pairs(nodes_train, llm, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)\n",
    "# val_dataset = generate_qa_embedding_pairs(nodes_val, llm, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ec1f2f-45e5-4c90-b0bb-675fbf2494ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.save_json(\"data/riigikogu_w_meta/embedding_finetune/train_dataset.json\")\n",
    "# val_dataset.save_json(\"data/riigikogu_w_meta/embedding_finetune/val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b86771c1-23e1-49de-ba39-08761e95dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 920/2000 [1:24:43<1:39:27,  5.53s/it]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_qa_embedding_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_generate_prompt_tmpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqa_generate_prompt_tmpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/llama_index/finetuning/embeddings/common.py:87\u001b[0m, in \u001b[0;36mgenerate_qa_embedding_pairs\u001b[0;34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id, text \u001b[38;5;129;01min\u001b[39;00m tqdm(node_dict\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m     84\u001b[0m     query \u001b[38;5;241m=\u001b[39m qa_generate_prompt_tmpl\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     85\u001b[0m         context_str\u001b[38;5;241m=\u001b[39mtext, num_questions_per_chunk\u001b[38;5;241m=\u001b[39mnum_questions_per_chunk\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m     questions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     91\u001b[0m         re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[1;32m     92\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/llama_index/llms/base.py:223\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n\u001b[1;32m    214\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    215\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    216\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         },\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponseGen:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/llama_index/llms/openai.py:252\u001b[0m, in \u001b[0;36mOpenAI.complete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     complete_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/llama_index/llms/generic_utils.py:153\u001b[0m, in \u001b[0;36mchat_to_completion_decorator.<locals>.wrapper\u001b[0;34m(prompt, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     messages \u001b[38;5;241m=\u001b[39m prompt_to_messages(prompt)\n\u001b[0;32m--> 153\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/llama_index/llms/openai.py:289\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client()\n\u001b[1;32m    288\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[0;32m--> 289\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m openai_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    295\u001b[0m message \u001b[38;5;241m=\u001b[39m from_openai_message(openai_message)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/resources/chat/completions.py:648\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    647\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:1167\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1155\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1164\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1165\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1166\u001b[0m     )\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    855\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:932\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    931\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:932\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    931\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:932\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    931\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    946\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    950\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    951\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    955\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_qa_embedding_pairs(nodes_train, llm, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba18e97-17a4-414f-83ce-ed0d606c8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = generate_qa_embedding_pairs(nodes_val, llm, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e7331-574a-4898-9bfa-2052a235771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.save_json(\"data/riigikogu_w_meta/embedding_finetune/train_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1ff48-1296-44a5-a424-d87815ee2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fb132-8b97-48ef-9912-2c48298e8eb5",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c4ad6-4204-474e-9462-5325cbe075c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.save_json(\"data/riigikogu_w_meta/embedding_finetune/train_dataset.json\")\n",
    "val_dataset.save_json(\"data/riigikogu_w_meta/embedding_finetune/val_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf7675-234e-4166-aed3-7bd501a198da",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19411fa1-bac7-4fa2-b08b-b7a31276e23c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2de50-f677-470a-acc9-1944370728fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/riigikogu_w_meta/embedding_finetune/train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/riigikogu_w_meta/embedding_finetune/val_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94d679-7b45-40d0-9abf-579cca12a63e",
   "metadata": {},
   "source": [
    "## Run embedding finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77572a-5509-47ee-bcd1-a4cf92a197ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"intfloat/multilingual-e5-base\",\n",
    "    model_output_path=\"test_model\",\n",
    "    val_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fccb0-5335-4cb9-b0e7-97b55fec3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79baa7-1491-4a1c-9907-a25a97b2aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473b15c-b211-47d4-840a-31004d365e1b",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1dc03-9591-4ecc-b9d4-cbf63076d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdde69a-514e-4c38-b3a2-2c6953d7325f",
   "metadata": {},
   "source": [
    "Define eval function\n",
    "Option 1: We use a simple hit rate metric for evaluation:\n",
    "\n",
    "for each (query, relevant_doc) pair,\n",
    "\n",
    "we retrieve top-k documents with the query, and\n",
    "\n",
    "it’s a hit if the results contain the relevant_doc.\n",
    "\n",
    "This approach is very simple and intuitive, and we can apply it to both the proprietary OpenAI embedding as well as our open source and fine-tuned embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3b01c-b26a-44a1-a713-3e0a4f8955e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    dataset,\n",
    "    embed_model,\n",
    "    top_k=5,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(\n",
    "        nodes, service_context=service_context, show_progress=True\n",
    "    )\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9df97-a87d-40c0-adb7-a46542afc185",
   "metadata": {},
   "source": [
    "Option 2: We use the InformationRetrievalEvaluator from sentence_transformers.\n",
    "\n",
    "This provides a more comprehensive suite of metrics, but we can only run it against the sentencetransformers compatible models (open source and our finetuned model, not the OpenAI embedding model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167eadbe-8b23-40fc-93be-441e21b20cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def evaluate_st(\n",
    "    dataset,\n",
    "    model_id,\n",
    "    name,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(\n",
    "        queries, corpus, relevant_docs, name=name\n",
    "    )\n",
    "    model = SentenceTransformer(model_id)\n",
    "    output_path = \"results/\"\n",
    "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
    "    return evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035a097-bf57-4561-989c-b32c04338e60",
   "metadata": {},
   "source": [
    "## Eval openAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af43be7-3d56-4f7e-bb38-7d35d7bfca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = OpenAIEmbedding()\n",
    "ada_val_results = evaluate(val_dataset, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca381aaa-4d78-4820-b05e-b900762f08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada = pd.DataFrame(ada_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda4d9d-7373-467f-aa1b-ec3699e748db",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_ada = df_ada[\"is_hit\"].mean()\n",
    "hit_rate_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b3197-b4b2-4898-80ff-236c1d792373",
   "metadata": {},
   "source": [
    "## Local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3d3f4-df6f-400f-baed-92b6463f1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "bge = \"local:intfloat/multilingual-e5-base\"\n",
    "bge_val_results = evaluate(val_dataset, bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84aa46-121f-4baa-a9d9-59c31327850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bge = pd.DataFrame(bge_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73a28b-39fd-4ef1-810d-633d41de56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
    "hit_rate_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acded01d-4aac-454e-afa9-99193037c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_st(val_dataset, \"intfloat/multilingual-e5-base\", name=\"e5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f4808-8b4e-42cf-a6ed-1efb89df8f26",
   "metadata": {},
   "source": [
    "## Finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69109459-2021-4729-9047-ba4b986d6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = \"local:test_model\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47a137-52a7-483d-bf9f-5ef2189f93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned = pd.DataFrame(val_results_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69bd94-93b8-4091-85d8-9fe63168d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_finetuned = df_finetuned[\"is_hit\"].mean()\n",
    "hit_rate_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761a5e2-6914-4a55-a989-eeb6d677f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned[\"is_hit\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e3b04-d874-4865-96e9-303bc1f20c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_st(val_dataset, \"test_model\", name=\"finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c576a5c-5e37-4815-b462-8d509e82bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_e5=pd.read_csv('results/Information-Retrieval_evaluation_e5_results.csv')\n",
    "df_res_fine_tune=pd.read_csv('results/Information-Retrieval_evaluation_finetuned_results.csv')\n",
    "df_res_e5['model'] = 'e5'\n",
    "df_res_fine_tune['model'] = 'fine_tuned'\n",
    "df_st_all = pd.concat([df_res_e5, df_res_fine_tune])\n",
    "df_st_all = df_st_all.set_index('model')\n",
    "df_st_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd4f30-e404-435b-a5d5-088667a4b9e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Review some texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44cf8b-ba8c-4ee9-8ae2-08c3be7021ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5bc2b-3437-48fd-98a6-efa0ea28d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned[~df_finetuned.is_hit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b60e6-e535-4090-ae76-03776c7a7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected\n",
    "[n for n in nodes_val if n.id_=='dbcf0086-bef5-4ff9-8b0a-7099f1ed52d4'][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eb103-9bf9-4797-9210-ecbecfeba658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved\n",
    "[n for n in nodes_val if n.id_=='5a245ed8-716e-4b8e-9ec4-16c27c16daee'][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab8e38-4ec3-4685-af6e-3c8ff178f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved\n",
    "[n for n in nodes_val if n.id_=='b779c5d5-124b-4f36-9beb-900c0cbe2fe0'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b441a1d-715f-46e3-9b0f-dbb3d2339039",
   "metadata": {},
   "source": [
    "## Test finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ff845-3ab1-4f81-b62e-3390a01fc3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94c9b8-d2a9-4c4c-9cfd-888b61ae5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fintuned = SentenceTransformer('test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2e75b-4b42-4615-9593-54b7a7dc3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig=SentenceTransformer(\"intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211fc62-30a9-4deb-906c-9a57a799c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.speaker.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa785b60-69d0-412a-961f-36cf0d1a1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers2keep=['Rahandusminister Jürgen Ligi', 'Peaminister Taavi Rõivas', 'Rahandusminister Sven Sester', \n",
    "               'Majandus- ja kommunikatsiooniminister Juhan Parts', 'Henn Põlluaas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529bed2-12b7-4025-a374-e388bb50250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.speaker.isin(speakers2keep)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351c051-088a-46c2-845b-17bbb2d13de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=df[df.speaker.isin(speakers2keep)]\n",
    "df_sample.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9fc8ca-f4e4-4efd-a14b-d932bad58b04",
   "metadata": {},
   "source": [
    "#### Train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d13f37-6f58-4d03-b0ab-cd53896e231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df_sample.text_splitted.tolist()\n",
    "labels=df_sample.speaker.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef18d9-882d-475a-ba90-ad0ad9c5336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f01500-ff85-43ec-b143-397ceafdeea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_train_orig=model_orig.encode(X_train)\n",
    "embs_train_finet=model_fintuned.encode(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe89905-7e50-4210-aa1d-907565cbea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_test_orig=model_orig.encode(X_test)\n",
    "embs_test_finet=model_fintuned.encode(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9968cb-d74b-4a66-a4bb-bed7e7ee19d3",
   "metadata": {},
   "source": [
    "#### Train model originial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956da0eb-ad30-4df9-9cd0-47f92ff99080",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_orig=LinearSVC()\n",
    "clf_orig.fit(embs_train_orig, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080f42e-ebe2-41ed-93a5-f7ab4f0d4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict eval data\n",
    "pred_labels = clf_orig.predict(embs_test_orig)\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1bd0b-df2b-4bb3-85c4-27f38419645b",
   "metadata": {},
   "source": [
    "#### Train finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37760df-9cf8-498b-8389-a2703234d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_finet=LinearSVC()\n",
    "clf_finet.fit(embs_train_finet, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa59269-0914-4e9b-abc0-d3ac583d0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict eval data\n",
    "pred_labels = clf_finet.predict(embs_test_finet)\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fd590-9319-4e7f-89a9-01c5df43fa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1ec6906-4918-47a0-a4db-a20b459e8402",
   "metadata": {},
   "source": [
    "## Fine-tune a Two-Layer Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493c22a-616a-4028-9235-961fd3f80b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding_adapter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e93eb5-e378-4570-81b6-7f9c7c552cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires torch dependency\n",
    "from llama_index.embeddings.adapter_utils import TwoLayerNN\n",
    "\n",
    "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
    "from llama_index.embeddings import resolve_embed_model\n",
    "from llama_index.embeddings import AdapterEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2ed5d-17b6-4258-a2a6-66b701476e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_embed_model = resolve_embed_model(\"local:intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c354a-8a88-40a4-9a2e-30b7021bdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_model = TwoLayerNN(\n",
    "    768,  # input dimension\n",
    "    1024,  # hidden dimension\n",
    "    768,  # output dimension\n",
    "    bias=True,\n",
    "    add_residual=True,\n",
    ")\n",
    "\n",
    "finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    train_dataset,\n",
    "    base_embed_model,\n",
    "    model_output_path=\"modele5_output_test\",\n",
    "    model_checkpoint_path=\"model5_ck\",\n",
    "    adapter_model=adapter_model,\n",
    "    epochs=25,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea68824-81b2-4fa0-b332-d16a76e6127c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716b9d9-8c21-4b9b-b273-92854e68117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_2layer = finetune_engine.get_finetuned_model(\n",
    "    adapter_cls=TwoLayerNN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426798c8-3721-48a4-932c-59d597887791",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b1096-b200-4add-a4ed-bccad45246f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint in the midde\n",
    "embed_model_2layer = AdapterEmbeddingModel(\n",
    "    base_embed_model,\n",
    "    \"modele5_output_test\",\n",
    "    TwoLayerNN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d892434-53d1-4a3a-b9cd-38937573a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_val_results_2layer = evaluate(val_dataset, embed_model_2layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fc2b3-3d1c-48ff-97cd-f83de0b154ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ft_val_results_2layer).is_hit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7e9ef-532b-4a03-96d9-0281bc585a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ft_val_results_2layer).is_hit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8935b4-7a5a-44f6-841e-f902496ab5e6",
   "metadata": {},
   "source": [
    "## Use this model in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c9887-af59-4b9d-bb13-9fc5238776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_model_2layer.get_text_embedding(['see'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edf6d0-d5f6-4cc0-a633-c25a1f65bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_train_orig=model_orig.encode(X_train)\n",
    "embs_train_finet_cust=[embed_model_2layer.get_text_embedding(t) for t in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3548b0-17d1-4b39-9028-5b294f6705ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_test_orig=model_orig.encode(X_test)\n",
    "embs_test_finet_cust=[embed_model_2layer.get_text_embedding(t) for t in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ceb92b-940e-46c4-a844-ff79e36e3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_finet_cust=LinearSVC()\n",
    "clf_finet_cust.fit(embs_train_finet_cust, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43aa157-6058-4d2f-bf25-9f0af3effac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = clf_finet_cust.predict(embs_test_finet_cust)\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4a219-f195-4f83-9856-234b9195464c",
   "metadata": {},
   "source": [
    "## Custom adapter layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310c28f-b29b-44ca-9603-68804d0cd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.adapter_utils import BaseAdapter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0cf86-eedc-4a0b-8b82-05f7b3390053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(BaseAdapter):\n",
    "    \"\"\"Custom NN transformation.\n",
    "\n",
    "    Is a copy of our TwoLayerNN, showing it here for notebook purposes.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Input dimension.\n",
    "        hidden_features (int): Hidden dimension.\n",
    "        out_features (int): Output dimension.\n",
    "        bias (bool): Whether to use bias. Defaults to False.\n",
    "        activation_fn_str (str): Name of activation function. Defaults to \"relu\".\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        hidden_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = False,\n",
    "        add_residual: bool = False,\n",
    "    ) -> None:\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features, hidden_features, bias=True)\n",
    "        self.linear2 = nn.Linear(hidden_features, out_features, bias=True)\n",
    "        self._add_residual = add_residual\n",
    "        # if add_residual, then add residual_weight (init to 0)\n",
    "        self.residual_weight = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, embed: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass (Wv).\n",
    "\n",
    "        Args:\n",
    "            embed (Tensor): Input tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        output1 = self.linear1(embed)\n",
    "        output1 = F.relu(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "\n",
    "        if self._add_residual:\n",
    "            output2 = self.residual_weight * output2 + embed\n",
    "\n",
    "        return output2\n",
    "\n",
    "    def get_config_dict(self) -> Dict:\n",
    "        \"\"\"Get config dict.\"\"\"\n",
    "        return {\n",
    "            \"in_features\": self.in_features,\n",
    "            \"hidden_features\": self.hidden_features,\n",
    "            \"out_features\": self.out_features,\n",
    "            \"bias\": self.bias,\n",
    "            \"add_residual\": self._add_residual,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf5709-1d0f-416a-98a9-fb91e8996dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_adapter = CustomNN(\n",
    "    768,  # input dimension\n",
    "    2048,  # hidden dimension\n",
    "    768,  # output dimension\n",
    "    bias=True,\n",
    "    add_residual=True,\n",
    ")\n",
    "\n",
    "finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    train_dataset,\n",
    "    base_embed_model,\n",
    "    model_output_path=\"custom_modele5_output_test\",\n",
    "    model_checkpoint_path=\"custom_model_ck\",\n",
    "    adapter_model=custom_adapter,\n",
    "    epochs=25,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa914d-ef3e-4f88-8bf9-8bb3cda72de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549733b2-2bfe-4060-9f27-407666ccea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_custom = finetune_engine.get_finetuned_model(\n",
    "    adapter_cls=custom_adapter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d02f8-c5d0-4be5-80d0-3910110ecad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint in the midde\n",
    "embed_model_custom_ckp = AdapterEmbeddingModel(\n",
    "    base_embed_model,\n",
    "    \"custom_model_ck/step_000\",\n",
    "    CustomNN,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf3b30-7515-4865-bb60-4b5284a3c8bb",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f382773-731c-46d4-a209-623b30c0b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_val_results_custom = evaluate(val_dataset, embed_model_custom_ckp)\n",
    "pd.DataFrame(ft_val_results_custom).is_hit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc4333-c0ed-4b4c-8dd6-7e460eb187f0",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c53aa5-43d4-41ce-94f4-a1a3a32e90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_train_orig=model_orig.encode(X_train)\n",
    "embs_train_finet_cust_v2=[embed_model_custom_ckp.get_text_embedding(t) for t in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fed42f-9021-43ee-b5cb-e8f1651a45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_test_orig=model_orig.encode(X_test)\n",
    "embs_test_finet_cust_v2=[embed_model_custom_ckp.get_text_embedding(t) for t in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcba352-59d7-454c-89b2-c61e2a13f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_finet_cust_v2=LinearSVC()\n",
    "clf_finet_cust_v2.fit(embs_train_finet_cust_v2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818557c-3df2-461b-92f3-341bc20cc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = clf_finet_cust_v2.predict(embs_test_finet_cust_v2)\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea6ccc-f7fa-48a0-b591-79c4a48f2296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ffe10-2310-4665-b594-90dd6bba8617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
