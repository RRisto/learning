{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9944b7cd-4843-438b-a626-80f7d257bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from pydantic import create_model\n",
    "import inspect, json\n",
    "from inspect import Parameter\n",
    "from configparser import ConfigParser\n",
    "from fastcore.utils import nested_idx\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce9867f-6aab-43f6-a9fc-b6919dde1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastcore\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6df3bb-e3b7-4bff-a57e-4a5043860cb9",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4229a836-e22f-4d9e-987b-75a9bb351ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=ConfigParser()\n",
    "config.read('conf/conf.ini')\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai']['apikey']\n",
    "\n",
    "client = OpenAI()\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2674e9b1-7b95-4ec2-8dcb-50c92725b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
    "    msgs = []\n",
    "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
    "    msgs.append({\"role\": \"user\", \"content\": user})\n",
    "    return client.chat.completions.create(model=model, messages=msgs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0129103b-d969-4487-a0a6-52c07b381537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(compl): print(nested_idx(compl, 'choices', 0, 'message', 'content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f624ef7-a111-4b39-8691-3575ae3d2f75",
   "metadata": {},
   "source": [
    "## Define function and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e4414a-8320-495a-a5d8-8a58fcfe37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(a:int, b:int=1):\n",
    "    \"Adds a + b\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31355af0-c555-4ceb-8640-0a1993a3b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema(f):\n",
    "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
    "          for n,o in inspect.signature(f).parameters.items()}\n",
    "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
    "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8eb41ef-223c-43e0-9afb-4f193a5126c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sums',\n",
       " 'description': 'Adds a + b',\n",
       " 'parameters': {'title': 'Input for `sums`',\n",
       "  'type': 'object',\n",
       "  'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "   'b': {'title': 'B', 'default': 1, 'type': 'integer'}},\n",
       "  'required': ['a']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ba878-9409-446b-a7bc-2049c1b1084b",
   "metadata": {},
   "source": [
    "## Show query to LLM and output how it as identified function adn arguments to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b206105a-8698-48cd-9ebd-00612e4c4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
    "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
    "           functions=[schema(sums)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9401f9c3-6fd7-409f-b028-c8cae8cee085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"a\": 6,\\n  \"b\": 3\\n}', name='sums'), tool_calls=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d09b4d-eb32-4ba8-ac81-6633f66c8106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c252207-d2b6-4b24-80ee-3d71b7dbf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = c.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "418be039-9be6-4c91-a632-b5e914a06884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"a\": 6,\n",
      "  \"b\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "k = m.function_call.arguments\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd3be4-ecc4-4b45-80eb-88fa1fc3b9cd",
   "metadata": {},
   "source": [
    "## Define ok funcs, not to have random funcs called by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37231444-090a-4e90-9762-d58845909965",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_ok = {'sums', 'python'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8fbf931-db65-49e2-bf6f-26b46a157304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_func(c):\n",
    "    fc = c.choices[0].message.function_call\n",
    "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
    "    f = globals()[fc.name]\n",
    "    return f(**json.loads(fc.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359d2ed8-67db-4acc-a161-bd4576a315d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ea83a9e-a23d-4ac3-80ac-68408bfcf163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(code):\n",
    "    tree = ast.parse(code)\n",
    "    last_node = tree.body[-1] if tree.body else None\n",
    "    \n",
    "    # If the last node is an expression, modify the AST to capture the result\n",
    "    if isinstance(last_node, ast.Expr):\n",
    "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
    "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
    "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
    "\n",
    "    ns = {}\n",
    "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
    "    return ns.get('_result', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "079f38e0-8d2f-495d-846b-605ab03c85ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "a=1\n",
    "b=2\n",
    "a+b\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbcf761a-7712-4eef-ad54-921c92a36c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python(code:str):\n",
    "    \"Return result of executing `code` using python. If execution not permitted, returns `#FAIL#`\"\n",
    "    go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
    "    if go.lower()!='y': return '#FAIL#'\n",
    "    return run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01f5683a-cb43-4a65-afbb-3b1ab7762ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"What is 12 factorial?\",\n",
    "           system = \"Use python for any required computations.\",\n",
    "           functions=[schema(python)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7a2548c-37ee-4a57-92b3-01aa72ea94b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Proceed with execution?\n",
      "```\n",
      "import math\n",
      "math.factorial(12)\n",
      "```\n",
      " y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "479001600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "209573b3-4c40-4202-b198-87de16e2ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    functions=[schema(python)],\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 12 factorial?\"},\n",
    "              {\"role\": \"function\", \"name\": \"python\", \"content\": \"479001600\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c7b3f2d-cccb-4ff7-a240-71dc8ba13f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 factorial, denoted as 12!, is the product of all positive integers from 1 to 12. \\n\\n12! = 12 × 11 × 10 × 9 × 8 × 7 × 6 × 5 × 4 × 3 × 2 × 1 = 479,001,600.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d7b6e-dbf3-49c9-8d14-a992e97690fe",
   "metadata": {},
   "source": [
    "## Dummy example with my function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "961f5df5-3bf9-4d9a-9cdd-c2c159cabb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_ok = {'find_trends', 'python'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de58861-3240-4b6b-a80a-02caca4c4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trends(first_period_start:str, first_period_end:str, \n",
    "                second_period_start:str, second_period_end:str,\n",
    "                channel:str):\n",
    "    \"\"\"Finds trends by comparing two time periods: first_period_start-first_period_end vs second_period_start-second_period_end in a specified channel\n",
    "    first_period_start - start of the first period, in format dd.mm.yyyy\n",
    "    first_period_end - end of the first period, in format dd.mm.yyyy\n",
    "    second_period_start - start of the second period, in format dd.mm.yyyy\n",
    "    second_period_end - end of the second period, in format dd.mm.yyyy\n",
    "    channel - name of the channel where to look for trends\"\"\"\n",
    "    if channel=='call':\n",
    "        return \"\"\"topic 'invoice' rose 12%, \n",
    "              topic 'payment' decreased 2%\"\"\" \n",
    "    else:\n",
    "        return \"something rose and something decreased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cc1f43f-e8a4-490e-9680-c369873c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"Find trends between 01.01.2023-05.01.2023 vs 01.02.2023-05.02.2023 in channel 'call'\",\n",
    "           #system = \"You must use the `sum` function instead of adding yourself.\",\n",
    "           functions=[schema(find_trends)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "536ad852-5755-4509-9374-d5f4a2c81a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8V0qNLfQwEeD5TK8YnVaZcZb2nZEl', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"first_period_start\": \"01.01.2023\",\\n  \"first_period_end\": \"05.01.2023\",\\n  \"second_period_start\": \"01.02.2023\",\\n  \"second_period_end\": \"05.02.2023\",\\n  \"channel\": \"call\"\\n}', name='find_trends'), tool_calls=None))], created=1702402103, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=72, prompt_tokens=212, total_tokens=284))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc2e6065-0d66-4e0f-a138-f3352579b8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"first_period_start\": \"01.01.2023\",\\n  \"first_period_end\": \"05.01.2023\",\\n  \"second_period_start\": \"01.02.2023\",\\n  \"second_period_end\": \"05.02.2023\",\\n  \"channel\": \"call\"\\n}', name='find_trends'), tool_calls=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d3e4a7-b34e-40dd-837e-9f5140f72ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{\\n  \"first_period_start\": \"01.01.2023\",\\n  \"first_period_end\": \"05.01.2023\",\\n  \"second_period_start\": \"01.02.2023\",\\n  \"second_period_end\": \"05.02.2023\",\\n  \"channel\": \"call\"\\n}', name='find_trends')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8577c19f-e210-437e-9a85-7212ebc50910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 'invoice' rose 12%, \n",
      "              topic 'payment' decreased 2%\n"
     ]
    }
   ],
   "source": [
    "print(call_func(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ee7779-88a3-4636-aad2-e15e11d07678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = askgpt(\"What is capital of France\",\n",
    "           #system = \"You must use the `sum` function instead of adding yourself.\",\n",
    "           functions=[schema(find_trends)])\n",
    "c.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df4b8f9b-a637-498b-84a9-35b124d99173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt_func_call(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
    "    msgs = []\n",
    "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
    "    msgs.append({\"role\": \"user\", \"content\": user})\n",
    "    c=client.chat.completions.create(model=model, messages=msgs, **kwargs)\n",
    "    \n",
    "    if c.choices[0].message.function_call is None:\n",
    "        return c.choices[0].message.content\n",
    "    func_call_out=call_func(c)\n",
    "    \n",
    "    msgs.append({\"role\": \"function\", \"name\": \"python\", \"content\": func_call_out})\n",
    "    c2=client.chat.completions.create(model=model, messages=msgs)\n",
    "    return c2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe65a51-be48-43f3-b331-7492b53f519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=askgpt_func_call(\"Find trends between 01.01.2023-05.01.2023 vs 01.02.2023-05.02.2023 in channel 'call'\",\n",
    "                functions=[schema(find_trends)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "937c6a25-c9a0-4533-bd5c-e70270e27943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the period from 01.01.2023-05.01.2023 to 01.02.2023-05.02.2023, there were some notable trends in the 'call' channel related to the topics of 'invoice' and 'payment'. \n",
      "\n",
      "The topic of 'invoice' experienced a significant rise of 12% during this period. This suggests that there was a higher volume of calls related to invoices in the later timeframe compared to the earlier timeframe.\n",
      "\n",
      "On the other hand, the topic of 'payment' witnessed a decrease of 2% in the later timeframe. This indicates that there were slightly fewer calls related to payments during the second period compared to the first period.\n",
      "\n",
      "Overall, these trends suggest that there was an increased focus on invoices and a slight decline in calls related to payments in the 'call' channel between 01.01.2023-05.01.2023 and 01.02.2023-05.02.2023.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32daee07-193d-4e5f-8fdf-9944b0c8a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7f05bc93fbe0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c88ff-73e5-4888-87bb-3fd79a5e23a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
