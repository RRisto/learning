{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48de7c7b-6f28-45b6-8c28-509f6c8add98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sentencepiece --quiet\n",
    "# !pip install sacrebleu --quiet\n",
    "# !pip install torchdata --quiet\n",
    "\n",
    "# !pip install --upgrade lxml\n",
    "## make restart to kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e989a4-18dc-4390-96d6-bed835ed845e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torchtext\n",
    "# !pip install einops\n",
    "# !pip install fastcore\n",
    "# !pip install fastprogress\n",
    "# !pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eaf8c7f-dbcb-4678-a7c1-c3cde0fd7af0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from copy import copy\n",
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from collections.abc import Mapping\n",
    "\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.datasets import Multi30k\n",
    "from tqdm import tqdm\n",
    "from operator import attrgetter,itemgetter\n",
    "import fastcore.all as fc\n",
    "from fastprogress import progress_bar,master_bar\n",
    "from torcheval.metrics import Mean\n",
    "\n",
    "from rotary_embedding.rotary_embedding_torch import RotaryEmbedding\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48c11df-326f-4f7c-a625-0283087ddbaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865da9ac-17c5-4e02-a50f-d699066532bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data treparation for tokenizer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f579ece-9cd2-436c-841b-6575fc9cd87d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SRC = \"de\"\n",
    "TRG = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509de075-a044-4bb7-b9b6-86397bc606b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC, TRG))\n",
    "f_de = open(\"Multi30k_de_text.txt\", \"w\")\n",
    "f_en = open(\"Multi30k_en_text.txt\", \"w\")\n",
    "for pair in train_iter:\n",
    "    f_de.write(pair[0]+'\\n')\n",
    "    f_en.write(pair[1]+'\\n')\n",
    "f_de.close()\n",
    "f_en.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bf09ee-f653-49dd-8915-df2baa8abccc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "en_vocab_size = 8200\n",
    "de_vocab_size = 10000\n",
    "vocab_sizes = {\"en\": en_vocab_size, \"de\": de_vocab_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0ff80-9b2f-49e9-82e2-44c6229bd92b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## train sentencepice models for tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08aaea03-8003-4106-8ca4-3f4f9592c4c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size=8200\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: Multi30k_en_text.txt\n",
      "  input_format: \n",
      "  model_prefix: Multi30k_en\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8200\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <pad>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: Multi30k_en_text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 29000 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=1801236\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9516% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=52\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999516\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 29000 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 25692 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 29000\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 15387\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 15387 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10170 obj=9.03356 num_tokens=30133 num_tokens/piece=2.96293\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8287 obj=7.02627 num_tokens=30222 num_tokens/piece=3.64692\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: Multi30k_en.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: Multi30k_en.vocab\n"
     ]
    }
   ],
   "source": [
    "txt_file1='Multi30k_en_text.txt'\n",
    "txt_file2='Multi30k_de_text.txt'\n",
    "model1_prefix='Multi30k_en'\n",
    "model2_prefix='Multi30k_de'\n",
    "vocab1_size=8200\n",
    "vocab2_size=10000\n",
    "spm.SentencePieceTrainer.train(f'--input={txt_file1} --model_prefix={model1_prefix} --user_defined_symbols=<pad> --vocab_size={vocab1_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31fec65d-f04b-49a5-b291-023520821876",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=Multi30k_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size=10000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: Multi30k_de_text.txt\n",
      "  input_format: \n",
      "  model_prefix: Multi30k_de\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <pad>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: Multi30k_de_text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 29000 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=2075871\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9552% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=59\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999552\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 29000 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 59750 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 29000\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 24824\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 24824 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16128 obj=10.2419 num_tokens=52489 num_tokens/piece=3.25453\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=13880 obj=7.87034 num_tokens=52837 num_tokens/piece=3.8067\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10982 obj=7.85011 num_tokens=55839 num_tokens/piece=5.08459\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10969 obj=7.81973 num_tokens=55870 num_tokens/piece=5.09345\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: Multi30k_de.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: Multi30k_de.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size=8200\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: Multi30k_en_text.txt\n",
      "  input_format: \n",
      "  model_prefix: Multi30k_en\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8200\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <pad>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: Multi30k_en_text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 29000 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=1801236\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9516% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=52\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999516\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 29000 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 25692 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 29000\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 15387\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 15387 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10170 obj=9.03356 num_tokens=30133 num_tokens/piece=2.96293\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8287 obj=7.02627 num_tokens=30222 num_tokens/piece=3.64692\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: Multi30k_en.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: Multi30k_en.vocab\n"
     ]
    }
   ],
   "source": [
    "class Tokenizers:\n",
    "    def __init__(self, sp1, sp2, vocab1_size, vocab2_size, lang1, lang2, model1_prefix, model2_prefix):\n",
    "        fc.store_attr()\n",
    "        self.tokenizers = {lang1: self.sp1.encode_as_ids, self.lang2: self.sp2.encode_as_ids}\n",
    "        self.detokenizers = {self.lang1: self.sp1.decode_ids, self.lang2: self.sp2.decode_ids}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_files(cls, txt_file1='Multi30k_en_text.txt', txt_file2='Multi30k_de_text.txt', model1_prefix='Multi30k_en',\n",
    "                   model2_prefix='Multi30k_de', vocab1_size=8200, vocab2_size=10000, lang1=\"en\", lang2=\"de\"):\n",
    "        spm.SentencePieceTrainer.train(f'--input={txt_file2} --model_prefix={model2_prefix} --user_defined_symbols=<pad> --vocab_size={vocab2_size}')\n",
    "        spm.SentencePieceTrainer.train(f'--input={txt_file1} --model_prefix={model1_prefix} --user_defined_symbols=<pad> --vocab_size={vocab1_size}')\n",
    "\n",
    "        # make SentencePieceProcessor instances and load the model files\n",
    "        sp2 = spm.SentencePieceProcessor()\n",
    "        sp2.load(f'{model2_prefix}.model')\n",
    "        sp1 = spm.SentencePieceProcessor()\n",
    "        sp1.load(f'{model1_prefix}.model')\n",
    "        \n",
    "        return cls(sp1=sp1, sp2=sp2, vocab1_size=8200, vocab2_size=10000, lang1=lang1, lang2=lang2, model1_prefix=model1_prefix, model2_prefix=model2_prefix)\n",
    "\n",
    "#         tokenizers = {\"en\": en_sp.encode_as_ids, \"de\": de_sp.encode_as_ids}\n",
    "#         detokenizers = {\"en\":en_sp.decode_ids, \"de\":de_sp.decode_ids}\n",
    "#         return tokenizers, detokenizers\n",
    "\n",
    "# def get_tokenizers(vocab_sizes={\"en\": 8200, \"de\": 10000}):\n",
    "#     spm.SentencePieceTrainer.train\\\n",
    "#     (f'--input=Multi30k_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n",
    "#     spm.SentencePieceTrainer.train\\\n",
    "#     (f'--input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n",
    "\n",
    "#     # make SentencePieceProcessor instances and load the model files\n",
    "#     de_sp = spm.SentencePieceProcessor()\n",
    "#     de_sp.load('Multi30k_de.model')\n",
    "#     en_sp = spm.SentencePieceProcessor()\n",
    "#     en_sp.load('Multi30k_en.model')\n",
    "\n",
    "#     tokenizers = {\"en\": en_sp.encode_as_ids, \"de\": de_sp.encode_as_ids}\n",
    "#     detokenizers = {\"en\":en_sp.decode_ids, \"de\":de_sp.decode_ids}\n",
    "#     return tokenizers, detokenizers\n",
    "\n",
    "# tokenizers, detokenizers=get_tokenizers()\n",
    "\n",
    "tokenizers=Tokenizers.from_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a49f8d9-2adc-4811-8433-ad0d7ad0a71c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # train sentencepiece models to get tokenizers\n",
    "# spm.SentencePieceTrainer.train\\\n",
    "# (f'--input=Multi30k_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n",
    "# spm.SentencePieceTrainer.train\\\n",
    "# (f'--input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n",
    "\n",
    "# # make SentencePieceProcessor instances and load the model files\n",
    "# de_sp = spm.SentencePieceProcessor()\n",
    "# de_sp.load('Multi30k_de.model')\n",
    "# en_sp = spm.SentencePieceProcessor()\n",
    "# en_sp.load('Multi30k_en.model')\n",
    "\n",
    "# tokenizers = {\"en\": en_sp.encode_as_ids, \"de\": de_sp.encode_as_ids}\n",
    "# detokenizers = {\"en\":en_sp.decode_ids, \"de\":de_sp.decode_ids}\n",
    "\n",
    "# encode: text => id\n",
    "# print(tokenizers[\"en\"]sp.encode_as_pieces('This is a test'))\n",
    "# print(en_sp.encode_as_ids('This is a test'))\n",
    "\n",
    "# # decode: id => text\n",
    "# print(en_sp.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n",
    "# print(en_sp.decode_ids([302, 258, 10, 4, 2395]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe1426c-c022-4369-aa36-1caf20875fa7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[302, 258, 10, 4, 2395]\n",
      "[302, 258, 10, 4, 2395]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizers.tokenizers[\"en\"]('This is a test'))\n",
    "print(tokenizers.sp1.encode_as_ids('This is a test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03eba4e1-e38a-406b-914a-d13015c07482",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁This is a test\n",
      "This is a test\n"
     ]
    }
   ],
   "source": [
    "print(tokenizers.sp1.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n",
    "print(tokenizers.sp1.decode_ids([302, 258, 10, 4, 2395]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b08793-7e4b-4c64-bc59-f2e364c41513",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<s>', '</s>', '<pad>', '▁a', '.', '▁A', '▁in', '▁the', '▁on', '▁is', '▁man', '▁and', '▁of', '▁with', 's', 'ing', '▁', ',', '▁woman']\n",
      "['<unk>', '<s>', '</s>', '<pad>', '.', '▁eine', '▁Ein', 'm', '▁in', '▁mit', ',', '▁und', '▁auf', '▁ein', '▁Mann', '▁einer', '▁Eine', 'n', '▁der', '▁Frau']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizers.sp1.id_to_piece(id) for id in range(20)])\n",
    "print([tokenizers.sp2.id_to_piece(id) for id in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08becd95-5d1c-421c-aef2-6e238c4d5a65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#indexes of special symbols\n",
    "# UNK, BOS, EOS, PAD = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f335a40-425a-4dff-8762-b9b41ca73ead",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preporcess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04b2fc9-d069-4316-856c-c3acb2b3a421",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_iter = Multi30k(split='train', language_pair=(SRC, TRG))\n",
    "# valid_iter = Multi30k(split='valid', language_pair=(SRC, TRG))\n",
    "# test_iter  = Multi30k(split='test',  language_pair=(SRC, TRG))\n",
    "\n",
    "# train_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in train_iter if x!='']\n",
    "# valid_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in valid_iter if x!='']\n",
    "# test_set  = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in test_iter if x!='']\n",
    "# print(len(train_set), len(valid_set), len(test_set))\n",
    "# for i in range(10):\n",
    "#     print(train_set[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bf1d7-a7d8-482b-a1a4-158fb073b08a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc08b6cb-89f5-43a3-891f-3aa83f3764eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_seq_len = 50\n",
    "def tokenize_dataset(dataset, src, trg, bos_id, eos_id, tokenizers, max_seq_len=50):\n",
    "    'tokenize a dataset and add [BOS] and [EOS] to the beginning and end of the sentences'\n",
    "    return [(torch.tensor([bos_id]+tokenizers.tokenizers[src](src_text)[0:max_seq_len-2]+[eos_id]),\n",
    "             torch.tensor([bos_id]+tokenizers.tokenizers[trg](trg_text)[0:max_seq_len-2]+[eos_id]))\n",
    "            for src_text, trg_text in dataset]\n",
    "          \n",
    "# train_tokenized = tokenize_dataset(train_set)\n",
    "# valid_tokenized = tokenize_dataset(valid_set)\n",
    "# test_tokenized  = tokenize_dataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1625a-cd0b-4e79-84db-52a94e7f5416",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc92014-8ec2-4afd-a6a9-04a70d39636e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    'create a dataset for torch.utils.data.DataLoader() '\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def pad_sequence(batch, pad_id):\n",
    "    'collate function for padding sentences such that all \\\n",
    "    the sentences in the batch have the same length'\n",
    "    src_seqs  = [src for src, trg in batch]\n",
    "    trg_seqs  = [trg for src, trg in batch]\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs,\n",
    "                                batch_first=True, padding_value = pad_id)\n",
    "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs,\n",
    "                                batch_first=True, padding_value = pad_id)\n",
    "    return src_padded, trg_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5371dd-299e-4bc5-a339-5d54bf7019fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41d06fa0-531b-4324-8e30-f8df04059785",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoaders:\n",
    "    def __init__(self, unk_id, bos_id, eos_id, pad_id, batch_size, max_seq_len, *dls): \n",
    "        self.train, self.valid, self.test = dls[:3]\n",
    "        self.unk_id, self.bos_id, self.eos_id, self.pad_id=unk_id, bos_id, eos_id, pad_id\n",
    "        self.batch_size, self.max_seq_len = batch_size, max_seq_len\n",
    "\n",
    "    @classmethod\n",
    "    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n",
    "        # return cls(*[DataLoader(ds, batch_size, collate_fn=collate_dict(ds), **kwargs) for ds in dd.values()])\n",
    "        return cls(*[torch.utils.data.DataLoader(TranslationDataset(ds), batch_size=batch_size,\n",
    "                                                shuffle=True, collate_fn = pad_sequence,  **kwargs) for ds in dd])\n",
    "    \n",
    "    @classmethod\n",
    "    def from_iters(cls, train_iter, valid_iter, test_iter, src, trg, tokenizers, batch_size=128, max_seq_len=50, as_tuple=True, \n",
    "                   unk_id=0, bos_id=1, eos_id=2, pad_id=3, **kwargs):\n",
    "        train_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in train_iter if x!='']\n",
    "        valid_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in valid_iter if x!='']\n",
    "        test_set  = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in test_iter if x!='']\n",
    "        \n",
    "        train_tokenized = tokenize_dataset(train_set, src, trg, bos_id, eos_id, tokenizers, max_seq_len)\n",
    "        valid_tokenized = tokenize_dataset(valid_set, src, trg, bos_id, eos_id, tokenizers, max_seq_len)\n",
    "        test_tokenized  = tokenize_dataset(test_set, src, trg, bos_id, eos_id, tokenizers, max_seq_len)\n",
    "        pad_sequence_partial=partial(pad_sequence, pad_id=pad_id)\n",
    "        return cls(unk_id, bos_id, eos_id, pad_id, batch_size, max_seq_len, \n",
    "                   *[torch.utils.data.DataLoader(TranslationDataset(ds), batch_size=batch_size,\n",
    "                                                 shuffle=True, collate_fn = pad_sequence_partial,  **kwargs) \\\n",
    "                     for ds in (train_tokenized, valid_tokenized, test_tokenized)])\n",
    "        \n",
    "def get_dls(src, trg, tokenizers, batch_size=128, max_seq_len=50):\n",
    "    train_iter = Multi30k(split='train', language_pair=(src, trg))\n",
    "    valid_iter = Multi30k(split='valid', language_pair=(src, trg))\n",
    "    test_iter  = Multi30k(split='test',  language_pair=(src, trg))\n",
    "    dls=DataLoaders.from_iters(train_iter, valid_iter, test_iter, src, trg, tokenizers, batch_size, max_seq_len)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56470fb2-dfb9-4646-b188-f69a4195adf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dls=get_dls(SRC, TRG, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c34937d-54d7-4233-baa6-274831e53384",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# next(iter(dls.train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07eb154-1104-4b6e-b223-7555f7ddf41b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc8a5f5-2892-4265-b0d4-418538670e69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0, use_rot_emb=True):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0 # check the h number\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_rot_emb=use_rot_emb\n",
    "        if use_rot_emb:\n",
    "            self.rotary_emb = RotaryEmbedding(dim = self.d_k//2)\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        nbatch = x_query.size(0) # get batch size\n",
    "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
    "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
    "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        if self.use_rot_emb:\n",
    "            query = self.rotary_emb.rotate_queries_or_keys(query)\n",
    "            key = self.rotary_emb.rotate_queries_or_keys(key)\n",
    "        # 2) Attention\n",
    "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
    "        # 3) Mask out padding tokens and future tokens\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
    "        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(p_atten)\n",
    "        # x dimensions: nbatch * h * seq_len * d_k\n",
    "        x = torch.matmul(p_atten, value)\n",
    "        # x now has dimensions:nbtach * seq_len * d_embed\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "        return self.linear(x) # final linear layer\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "    def __init__(self, dim, dropout):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.drop(sublayer(self.norm(x)))\n",
    "\n",
    "# I simply let the model learn the positional embeddings in this notebook, since this \n",
    "# almost produces identital results as using sin/cosin functions embeddings, as claimed\n",
    "# in the original transformer paper. Note also that in the original paper, they multiplied \n",
    "# the token embeddings by a factor of sqrt(d_embed), which I do not do here. \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        x = self.tok_embed(input)\n",
    "        x_pos = self.pos_embed[:, :x.size(1), :]\n",
    "        x = self.dropout(x + x_pos)\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
    "    def __init__(self, config):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout, config.use_rot_emb)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
    "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self-attention\n",
    "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
    "        # position-wise fully connected feed-forward layer\n",
    "        return self.residual2(x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
    "    \n",
    "    def future_mask(self, seq_len):\n",
    "        '''mask out tokens at future positions'''\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "\n",
    "    def forward(self, memory, src_mask, trg, trg_pad_mask):\n",
    "        seq_len = trg.size(1)\n",
    "        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n",
    "        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_blocks:\n",
    "            x = layer(memory, src_mask, x, trg_mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.atten1 = MultiHeadedAttention(config.h, config.d_embed, use_rot_emb=config.use_rot_emb)\n",
    "        self.atten2 = MultiHeadedAttention(config.h, config.d_embed, use_rot_emb=config.use_rot_emb)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n",
    "                                       for i in range(3)])\n",
    "\n",
    "    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n",
    "        x = memory\n",
    "        y = decoder_layer_input\n",
    "        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n",
    "        # keys and values are from the encoder output\n",
    "        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n",
    "        return self.residuals[2](y, self.feed_forward)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, src_mask, trg, trg_pad_mask):\n",
    "        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46be77f1-0693-43f4-a15b-8a3a1ace411e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    encoder_vocab_size: int\n",
    "    decoder_vocab_size: int\n",
    "    d_embed: int\n",
    "    use_rot_emb: bool\n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_encoder: int\n",
    "    N_decoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "    pad_id: int\n",
    "    unk_id: int\n",
    "    bos_id: int\n",
    "    eos_id: int\n",
    "\n",
    "def make_model(config, device='cuda'):\n",
    "    model = Transformer(Encoder(config), Decoder(config)).to(device)\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    model.pad_id=config.pad_id\n",
    "    model.unk_id=config.unk_id\n",
    "    model.bos_id=config.bos_id\n",
    "    model.eos_id=config.eos_id\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b8c3e-4715-4e3e-8463-eaf82c8d7f5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc3cd581-1867-426a-b948-63a8d8243b22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CancelFitException(Exception): \n",
    "    pass\n",
    "class CancelBatchException(Exception): \n",
    "    pass\n",
    "class CancelEpochException(Exception): \n",
    "    pass\n",
    "\n",
    "class Callback(): \n",
    "    order = 0\n",
    "    \n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None: \n",
    "            # print(method)\n",
    "            method(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab31fdc-bb1b-4761-8386-4c4e40a0d688",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c28a758c-6027-4690-b2ac-95bdd53077bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_batch_input(batch, device, pad_id):\n",
    "    x, y = batch[0], batch[1]\n",
    "    src = x.to(device)\n",
    "    trg_in = y[:, :-1].to(device)\n",
    "    trg_out = y[:, 1:].contiguous().view(-1).to(device)\n",
    "    src_pad_mask = (src == pad_id).view(src.size(0), 1, 1, src.size(-1))\n",
    "    trg_pad_mask = (trg_in == pad_id).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
    "    return {'src':src, 'trg_in':trg_in, 'trg_out':trg_out, 'src_pad_mask':src_pad_mask, 'trg_pad_mask':trg_pad_mask}\n",
    "    \n",
    "    \n",
    "class TrainCB(Callback):\n",
    "    def __init__(self, grad_acc_steps=1):\n",
    "        super(Callback, self).__init__()\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def predict(self, learn): \n",
    "        learn.batch = make_batch_input(learn.batch, learn.device, learn.model.pad_id)\n",
    "        preds = learn.model(learn.batch['src'], learn.batch['src_pad_mask'], learn.batch['trg_in'], learn.batch['trg_pad_mask'])\n",
    "        learn.preds = preds.view(-1, preds.size(-1))\n",
    "        \n",
    "    def get_loss(self, learn):\n",
    "        learn.loss_func(learn)\n",
    "        \n",
    "    def backward(self, learn):\n",
    "        learn.loss.backward()\n",
    "            \n",
    "    def step(self, learn): \n",
    "        learn.opt.step()\n",
    "        \n",
    "    def zero_grad(self, learn):\n",
    "        learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b1a2254-691c-41da-8267-fa5eb50c95a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, dls, loss_func=None, lr=0.1, cbs=None, device='cuda', opt_func=torch.optim.Adam):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "\n",
    "    @contextmanager\n",
    "    def callback_ctx(self, nm):\n",
    "        try:\n",
    "            self.callback(f'before_{nm}')\n",
    "            yield\n",
    "            self.callback(f'after_{nm}')\n",
    "        except globals()[f'Cancel{nm.title()}Exception']: \n",
    "            pass\n",
    "        finally: \n",
    "            self.callback(f'cleanup_{nm}')\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.train(train)\n",
    "        \n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        # pdb.set_trace()\n",
    "        with self.callback_ctx('epoch'):\n",
    "            for self.iter,self.batch in enumerate(self.dl):\n",
    "                with self.callback_ctx('batch'):\n",
    "                    self.predict()\n",
    "                    self.callback('after_predict')\n",
    "                    self.get_loss()\n",
    "                    self.callback('after_loss')\n",
    "                    if self.training:\n",
    "                        self.backward()\n",
    "                        self.callback('after_loss')\n",
    "                        self.step()\n",
    "                        self.callback('after_step')\n",
    "                        self.zero_grad()\n",
    "    \n",
    "    def fit(self, n_epochs=1, train=True, valid=False, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        for cb in cbs: \n",
    "            self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr if lr is None else lr)\n",
    "            # pdb.set_trace()\n",
    "            with self.callback_ctx('fit'):\n",
    "                for self.epoch in self.epochs:\n",
    "                    if train: \n",
    "                        self.one_epoch(True)\n",
    "                    if valid: \n",
    "                        torch.no_grad()(self.one_epoch)(False)\n",
    "        finally:\n",
    "            for cb in cbs: \n",
    "                self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): \n",
    "            return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): \n",
    "        run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): \n",
    "        return self.model.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9439c01-b6f7-4c4d-862c-26d8216d5fb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Progress cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a0fa62-a826-468e-995c-c6d006cf05d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping): \n",
    "        return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list): \n",
    "        return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): \n",
    "        return tuple(to_cpu(list(x)))\n",
    "    return x.detach().cpu()\n",
    "\n",
    "\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: \n",
    "            metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "        \n",
    "    def _log(self, d): \n",
    "        print(d)\n",
    "        \n",
    "    def before_fit(self, learn): \n",
    "        learn.metrics = self\n",
    "        \n",
    "    def before_epoch(self, learn): \n",
    "        [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        batch = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): \n",
    "            m.update(to_device(batch), learn)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(batch))\n",
    "        \n",
    "        \n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): \n",
    "        self.plot = plot\n",
    "        \n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): \n",
    "            learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "\n",
    "    def before_epoch(self, learn): \n",
    "        learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "        \n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            self.mbar.update_graph([[fc.L.range(self.losses), self.losses]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf50cb4-96c8-4b1e-9b99-9e4d2f566dfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loss calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d139b1-4fc3-4131-89f7-29431394b9ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss():\n",
    "    def __init__(self, loss_fun):\n",
    "        self.loss_fun=loss_fun()\n",
    "\n",
    "    def calc_loss(self, learn): \n",
    "        trg_out=learn.batch['trg_out']\n",
    "        loss=self.loss_fun(learn.preds, trg_out)\n",
    "        learn.loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43afdcbd-fe34-45a7-b26a-2e3d8d2f3654",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss_cl=CustomLoss(partial(nn.CrossEntropyLoss, ignore_index=PAD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fab565f-cd80-49d5-b54f-a3c6693863ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f10a34ee-02b4-4573-b8a4-b1bba6449125",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pr=partial(nn.CrossEntropyLoss, ignore_index=PAD)\n",
    "# pr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4a90f-57f2-4e49-be0b-ebf14f0f0602",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "077037b4-96b4-4113-bf81-ff584c969ea3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GradientClipping(Callback):\n",
    "    order=2\n",
    "    def __init__(self, grad_norm_clip=1.0):\n",
    "        self.grad_norm_clip=grad_norm_clip\n",
    "        \n",
    "    def after_loss(self, learn):\n",
    "        torch.nn.utils.clip_grad_norm_(learn.model.parameters(), self.grad_norm_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31af5e3-b84f-46d8-a5f5-e70b79719ad9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5deea42-1c16-4cd1-bb97-41b4032c0829",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseSchedCB(Callback):\n",
    "    def __init__(self, sched): \n",
    "        self.sched = sched\n",
    "        self.lrs=[]\n",
    "        \n",
    "    def before_fit(self, learn): \n",
    "        self.schedo = self.sched(learn.opt)\n",
    "        \n",
    "    def step_(self, learn):\n",
    "        if learn.training: \n",
    "            self.schedo.step()\n",
    "            self.lrs.append(self.schedo.get_last_lr()[0])\n",
    "        \n",
    "class BatchSchedCB(BaseSchedCB):\n",
    "    def after_batch(self, learn):\n",
    "        self.step_(learn) \n",
    "        \n",
    "        \n",
    "class EpochSchedCB(BaseSchedCB):\n",
    "    def after_epoch(self, learn):\n",
    "        if learn.training: \n",
    "            self.step_(learn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd414aa-d50e-4e82-9bdc-919e3fb4c483",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set parameters and callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "365a292c-e89b-4564-a280-a915a07d099a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataloaders\n",
    "batch_size = 128\n",
    "max_seq_len=50\n",
    "dls=get_dls(SRC, TRG, tokenizers, batch_size, max_seq_len)\n",
    "\n",
    "#model config\n",
    "config = ModelConfig(encoder_vocab_size = vocab_sizes[SRC], \n",
    "                     decoder_vocab_size=vocab_sizes[TRG],\n",
    "                     d_embed=512,\n",
    "                     use_rot_emb=True,\n",
    "                     d_ff=512, \n",
    "                     h=8,\n",
    "                     N_encoder=3, \n",
    "                     N_decoder=3, \n",
    "                     max_seq_len=max_seq_len,\n",
    "                     dropout=0.1,\n",
    "                     pad_id=dls.pad_id,\n",
    "                     unk_id=dls.unk_id,\n",
    "                     bos_id=dls.bos_id,\n",
    "                     eos_id=dls.eos_id)\n",
    "\n",
    "model = make_model(config)\n",
    "\n",
    "#optimizer\n",
    "lr=0.5\n",
    "optimizer_func = partial(torch.optim.Adam, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "#lr scheduler\n",
    "warmup_steps = 3*len(dls.train)\n",
    "# lr first increases in the warmup steps, and then decreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])  \n",
    "lr_scheduler = partial(torch.optim.lr_scheduler.LambdaLR, lr_lambda=lr_fn)\n",
    "#loss\n",
    "loss_cl=CustomLoss(partial(nn.CrossEntropyLoss, ignore_index=dls.pad_id))\n",
    "loss_func=loss_cl.calc_loss\n",
    "\n",
    "grad_norm_clip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7ea9e67-84e7-46ae-904a-8e916703bc43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#init callbacks\n",
    "cbs = [TrainCB(),\n",
    "       BatchSchedCB(lr_scheduler), \n",
    "       GradientClipping(grad_norm_clip),\n",
    "       MetricsCB(),\n",
    "       ProgressCB(plot=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d797b-8318-4f5c-95ee-afee12e17a50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a2607d-5bf6-44df-b929-4ee9f6add6f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learner = Learner(model, dls, loss_func, lr, cbs, opt_func=optimizer_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2924a42-75dd-4f2e-9fd1-3572a0668fab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "980a4ca7-f95e-4856-a98e-30be4f85e3ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5.512</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.560</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.929</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.382</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.056</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.951</td>\n",
       "      <td>2</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_epochs=3\n",
    "learner.fit(N_epochs, valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c78147-4f94-43be-a085-120b2614f188",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ddbb58b-0e10-4e5b-a1b5-b2c3378c7250",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate(model, x, pad_id, device='cuda'):\n",
    "    'translate source sentences into the target language, without looking at the answer'\n",
    "    with torch.no_grad():\n",
    "        dB = x.size(0)\n",
    "        y = torch.tensor([[model.bos_id]*dB]).view(dB, 1).to(device)\n",
    "        x_pad_mask = (x == model.pad_id).view(x.size(0), 1, 1, x.size(-1)).to(device)\n",
    "        memory = model.encoder(x, x_pad_mask)\n",
    "        for i in range(max_seq_len):\n",
    "            y_pad_mask = (y == pad_id).view(y.size(0), 1, 1, y.size(-1)).to(device)\n",
    "            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
    "            last_output = logits.argmax(-1)[:, -1]\n",
    "            last_output = last_output.view(dB, 1)\n",
    "            y = torch.cat((y, last_output), 1).to(device)\n",
    "    return y\n",
    "\n",
    "def remove_pad(sent, eos_id, pad_id):\n",
    "    '''truncate the sentence if BOS is in it,\n",
    "     otherwise simply remove the padding tokens at the end'''\n",
    "    if sent.count(eos_id)>0:\n",
    "        sent = sent[0:sent.index(eos_id)+1]\n",
    "    while sent and sent[-1] == pad_id:\n",
    "        sent = sent[:-1]\n",
    "    return sent\n",
    "\n",
    "def decode_sentence(detokenizer, sentence_ids, eos_id, pad_id):\n",
    "    'convert a tokenized sentence (a list of numbers) to a literal string'\n",
    "    if not isinstance(sentence_ids, list):\n",
    "        sentence_ids = sentence_ids.tolist()\n",
    "    sentence_ids = remove_pad(sentence_ids, eos_id, pad_id)\n",
    "    return detokenizer(sentence_ids).replace(\"<bos>\", \"\")\\\n",
    "           .replace(\"<eos>\", \"\").strip().replace(\" .\", \".\")\n",
    "\n",
    "def evaluate(model, dataloader, eos_id, pad_id, src_lang, trg_lang, detokenizers, num_batch=None, device='cuda'):\n",
    "    'evaluate the model, and compute the BLEU score'\n",
    "    model.eval()\n",
    "    refs, cans, bleus = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            batch = make_batch_input([x, y], device, pad_id)\n",
    "            translation = translate(model, batch[\"src\"], pad_id)\n",
    "            batch[\"trg_out\"] = batch[\"trg_out\"].view(x.size(0), -1)\n",
    "            refs = refs + [decode_sentence(detokenizers[trg_lang], batch['trg_out'][i], eos_id, pad_id) for i in range(len(batch[\"src\"]))]\n",
    "            cans = cans + [decode_sentence(detokenizers[trg_lang], translation[i], eos_id, pad_id) for i in range(len(batch[\"src\"]))] \n",
    "            if num_batch and idx>=num_batch:\n",
    "                break\n",
    "        print(min([len(x) for x in refs]))\n",
    "        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n",
    "        # print some examples\n",
    "        for i in range(3):\n",
    "            print(f'src:  {decode_sentence(detokenizers[src_lang], batch[\"src\"][i], eos_id, pad_id)}')\n",
    "            print(f'trg:  {decode_sentence(detokenizers[trg_lang], batch[\"trg_out\"][i], eos_id, pad_id)}')\n",
    "            print(f'pred: {decode_sentence(detokenizers[trg_lang], translation[i], eos_id, pad_id)}')\n",
    "        return np.mean(bleus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2b5c169-281e-4f0f-b35e-3477803c41c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def make_batch_input(batch, device, pad_id):\n",
    "#     x, y = batch[0], batch[1]\n",
    "#     src = x.to(device)\n",
    "#     trg_in = y[:, :-1].to(device)\n",
    "#     trg_out = y[:, 1:].contiguous().view(-1).to(device)\n",
    "#     src_pad_mask = (src == pad_id).view(src.size(0), 1, 1, src.size(-1))\n",
    "#     trg_pad_mask = (trg_in == pad_id).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
    "#     return {'src':src, 'trg_in':trg_in, 'trg_out':trg_out, 'src_pad_mask':src_pad_mask, 'trg_pad_mask':trg_pad_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91e839b3-a156-4259-b8ef-8fd102b2ca17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def make_batch_input(x, y):\n",
    "#         src = x.to(DEVICE)\n",
    "#         trg_in = y[:, :-1].to(DEVICE)\n",
    "#         trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n",
    "#         src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n",
    "#         trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
    "#         return src, trg_in, trg_out, src_pad_mask, trg_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d44c3be3-a413-4605-b4aa-cf30e6879b88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set examples:\n",
      "19\n",
      "src:  Zwei Frauen in einem Badezimmer, eine von ihnen hat einen Besen.\n",
      "trg:  Two women are in a bathroom and one has a broom.\n",
      "pred: Two women in a bathroom, one has a broom.\n",
      "src:  Leute sitzen in einem Restaurant mit hohen Decken und großen Fenstern, trinken verschiedene Weine und reden miteinander.\n",
      "trg:  People sit in a restaurant with tall ceilings and large windows drinking various wines and socializing.\n",
      "pred: People sitting in a restaurant with tall flower and large windows, drinking various wine and talking.\n",
      "src:  Ein Mann lächelt während er eine Akustikgitarre hält.\n",
      "trg:  A man smiling while holding an acoustic guitar.\n",
      "pred: A man smiles while he holds an acoustic guitar.\n",
      "validation set examples:\n",
      "20\n",
      "src:  Eine Frau und ein kleines Kind haben Spaß bei einem Brettspiel.\n",
      "trg:  A woman and a young child has fun while playing a board game.\n",
      "pred: A woman and a small child enjoying a board game.\n",
      "src:  Ein brauner Hund rennt dem schwarzen Hund hinterher.\n",
      "trg:  A brown dog is running after the black dog.\n",
      "pred: A brown dog runs after the black dog.\n",
      "src:  Ein Mann mit einer grauen Mütze, Trägershirt und schwarzen Shorts macht einen Handstand.\n",
      "trg:  A man in a gray hat and tank top with black shorts doing a handstand.\n",
      "pred: A man in a gray hat and black shorts is doing a handstand a handstand.\n",
      "test set examples:\n",
      "21\n",
      "src:  Eine Frau mit Tattoos macht mit ihrem Handy ein Foto von einem Gemälde.\n",
      "trg:  A lady with tattoos is taking a picture of a painting with her smartphone.\n",
      "pred: A woman with tattoos is taking a picture of her cellphone.\n",
      "src:  Ein Junger Mann rutscht mit dem Skateboard über ein rosa Geländer.\n",
      "trg:  A young man skateboards off a pink railing.\n",
      "pred: A boy sliding across a pink railing with the skateboard.\n",
      "src:  Ein Wachmann hält Wache während seiner Schicht.\n",
      "trg:  A guard is on the look out while on duty.\n",
      "pred: A security guard is holding his earken juggling the violin.\n"
     ]
    }
   ],
   "source": [
    "print(\"train set examples:\")\n",
    "train_bleu = evaluate(model, dls.train, model.eos_id, model.pad_id, SRC, TRG, tokenizers.detokenizers, 20)\n",
    "print(\"validation set examples:\")\n",
    "valid_bleu = evaluate(model, dls.valid, model.eos_id, model.pad_id, SRC, TRG, tokenizers.detokenizers)\n",
    "print(\"test set examples:\")\n",
    "test_bleu  = evaluate(model, dls.test, model.eos_id, model.pad_id, SRC, TRG, tokenizers.detokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6e96829-42ce-4e75-ab39-778ded4ba4c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.1265705049587"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0da1739-1e86-4274-aae2-505d8f907d2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.63873959783741"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c09310d-416c-444b-a567-d910507cdb1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.52792424643638"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715daac2-0fd6-4380-bdc7-4ce0d7999911",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c85bb168-5646-498f-a4be-0fdda3fc6623",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate(model, x, device):\n",
    "    'translate source sentences into the target language, without looking at the answer'\n",
    "    with torch.no_grad():\n",
    "        dB = x.size(0)\n",
    "        y = torch.tensor([[model.bos_id]*dB]).view(dB, 1).to(device)\n",
    "        x_pad_mask = (x == model.pad_id).view(x.size(0), 1, 1, x.size(-1)).to(device)\n",
    "        memory = model.encoder(x, x_pad_mask).to(device)\n",
    "        for i in range(max_seq_len):\n",
    "            y_pad_mask = (y == model.pad_id).view(y.size(0), 1, 1, y.size(-1)).to(device)\n",
    "            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
    "            last_output = logits.argmax(-1)[:, -1]\n",
    "            last_output = last_output.view(dB, 1)\n",
    "            y = torch.cat((y, last_output), 1).to(device)\n",
    "    return y\n",
    "\n",
    "def translate_this_sentence(text: str, model, tokenizers, src, trg, device='cuda'):\n",
    "    'translate the source sentence in string formate into target language'\n",
    "    inp = torch.tensor([[model.bos_id] + tokenizers.tokenizers[src](text) + [model.eos_id]]).to(device)\n",
    "    output = translate(model, inp, device)\n",
    "    return decode_sentence(tokenizers.detokenizers[trg], output[0], model.eos_id, model.pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "493b9fe8-f098-4c63-8775-72c68f27bafc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A group of people standing in front of an apple.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "translate_this_sentence(\"Eine Gruppe von Menschen steht vor einem Iglu.\", model, tokenizers, SRC, TRG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea344b0-8943-4640-9c69-30e01578a2c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8d290-a1e4-4b72-8b17-decd23695692",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}