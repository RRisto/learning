{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLDA(object):\n",
    "    \n",
    "    def __init__(self, documents,nr_topics ):\n",
    "        self.documents=documents\n",
    "        self.nr_topics=nr_topics\n",
    "        self.distinct_words=None\n",
    "        self.count_distinct_words()\n",
    "        \n",
    "        self.D = len(self.documents)\n",
    "        self.W = len(self.distinct_words)\n",
    "        \n",
    "        self.document_topic_counts =None\n",
    "        self.count_document_topic()\n",
    "        \n",
    "        self.topic_word_counts =None\n",
    "        self.count_topic_word()\n",
    "        \n",
    "        self.topic_counts = None\n",
    "        self.count_topic()\n",
    "        \n",
    "        self.document_lengths =None\n",
    "        self.get_document_lengths()\n",
    "        \n",
    "        self.document_topics = None\n",
    "        self.init_document_topics()\n",
    "        \n",
    "        self.init_counts()\n",
    "        \n",
    "        self.nr_iter=None\n",
    "        self.topic_names=None\n",
    "        \n",
    "    def count_document_topic(self):\n",
    "        '''How many times each topic is assigned to each document'''\n",
    "        self.document_topic_counts = [Counter() for _ in self.documents]\n",
    "    \n",
    "    def count_topic_word(self):\n",
    "        self.topic_word_counts= [Counter() for _ in range(self.nr_topics)]\n",
    "    \n",
    "    def sample_from(self, weights):\n",
    "        \"\"\"returns i with probability weights[i] / sum(weights)\"\"\"\n",
    "        total = sum(weights)\n",
    "        rnd = total * random.random() # uniform between 0 and total\n",
    "        for i, w in enumerate(weights):\n",
    "            rnd -= w # return the smallest i such that\n",
    "            if rnd <= 0: \n",
    "                return i # weights[0] + ... + weights[i] >= rnd\n",
    "            \n",
    "    def count_topic(self):\n",
    "        '''The total number of words assigned to each topic'''\n",
    "        self.topic_counts= [0 for _ in range(self.nr_topics)]\n",
    "    \n",
    "    def get_document_lengths(self):\n",
    "        self.document_lengths= list(map(len, self.documents))\n",
    "    \n",
    "    def count_distinct_words(self):\n",
    "        self.distinct_words=set(word for document in self.documents for word in document)\n",
    "    \n",
    "    def p_topic_given_document(self, topic, d, alpha=0.1):\n",
    "        \"\"\"the fraction of words in document _d_\n",
    "        that are assigned to _topic_ (plus some smoothing)\"\"\"\n",
    "        return ((self.document_topic_counts[d][topic] + alpha) /\n",
    "                (self.document_lengths[d] + self.nr_topics * alpha))\n",
    "\n",
    "    def p_word_given_topic(self,word, topic, beta=0.1):\n",
    "        \"\"\"the fraction of words assigned to _topic_\n",
    "        that equal _word_ (plus some smoothing)\"\"\"\n",
    "        return ((self.topic_word_counts[topic][word] + beta) /\n",
    "                (self.topic_counts[topic] + self.W * beta))\n",
    "    \n",
    "    def init_document_topics(self):\n",
    "        random.seed(0)\n",
    "        self.document_topics = [[random.randrange(self.nr_topics) for word in document] for document in self.documents]\n",
    "\n",
    "    def init_counts(self):\n",
    "        for d in range(self.D):\n",
    "            for word, topic in zip(self.documents[d], self.document_topics[d]):\n",
    "                self.document_topic_counts[d][topic] += 1\n",
    "                self.topic_word_counts[topic][word] += 1\n",
    "                self.topic_counts[topic] += 1\n",
    "                \n",
    "    def topic_weight(self, d, word, k):\n",
    "        \"\"\"given a document and a word in that document,\n",
    "        return the weight for the kth topic\"\"\"\n",
    "        return self.p_word_given_topic(word, k) * self.p_topic_given_document(k, d)\n",
    "\n",
    "    def choose_new_topic(self, d, word):\n",
    "        return self.sample_from([self.topic_weight(d, word, k)\n",
    "                            for k in range(self.nr_topics)])\n",
    "\n",
    "    def train(self, nr_iter):  \n",
    "        self.nr_iter=nr_iter\n",
    "        for iter in range(self.nr_iter):\n",
    "            for d in range(self.D):\n",
    "                for i, (word, topic) in enumerate(zip(self.documents[d],\n",
    "                                                      self.document_topics[d])):\n",
    "\n",
    "                    # remove this word / topic from the counts\n",
    "                    # so that it doesn't influence the weights\n",
    "                    self.document_topic_counts[d][topic] -= 1\n",
    "                    self.topic_word_counts[topic][word] -= 1\n",
    "                    self.topic_counts[topic] -= 1\n",
    "                    self.document_lengths[d] -= 1\n",
    "\n",
    "                    # choose a new topic based on the weights\n",
    "                    new_topic = self.choose_new_topic(d, word)\n",
    "                    self.document_topics[d][i] = new_topic\n",
    "\n",
    "                    # and now add it back to the counts\n",
    "                    self.document_topic_counts[d][new_topic] += 1\n",
    "                    self.topic_word_counts[new_topic][word] += 1\n",
    "                    self.topic_counts[new_topic] += 1\n",
    "                    self.document_lengths[d] += 1\n",
    "                    \n",
    "    def top_words_per_topic(self):\n",
    "        for k, word_counts in enumerate(self.topic_word_counts):\n",
    "            for word, count in word_counts.most_common():\n",
    "                if count > 0: \n",
    "                    print(k, word, count)\n",
    "    \n",
    "    def assign_topics(self, topic_names):\n",
    "        self.topic_names=topic_names\n",
    "        for document, topic_counts in zip(self.documents, self.document_topic_counts):\n",
    "            print(document)\n",
    "            for topic, count in topic_counts.most_common():\n",
    "                if count > 0:\n",
    "                    \n",
    "                    print(self.topic_names[topic], count)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model=CustomLDA(documents, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model.train(nr_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Java 3\n",
      "0 Big Data 3\n",
      "0 Hadoop 2\n",
      "0 Storm 1\n",
      "0 HBase 1\n",
      "0 deep learning 1\n",
      "0 Cassandra 1\n",
      "0 C++ 1\n",
      "0 programming languages 1\n",
      "0 Spark 1\n",
      "0 MapReduce 1\n",
      "1 neural networks 2\n",
      "1 machine learning 2\n",
      "1 Postgres 2\n",
      "1 HBase 2\n",
      "1 MongoDB 2\n",
      "1 scipy 1\n",
      "1 numpy 1\n",
      "1 MySQL 1\n",
      "1 deep learning 1\n",
      "1 NoSQL 1\n",
      "1 Cassandra 1\n",
      "1 decision trees 1\n",
      "1 artificial intelligence 1\n",
      "1 databases 1\n",
      "2 regression 3\n",
      "2 Python 2\n",
      "2 libsvm 2\n",
      "2 R 2\n",
      "2 scikit-learn 2\n",
      "2 support vector machines 1\n",
      "2 Haskell 1\n",
      "2 Mahout 1\n",
      "2 mathematics 1\n",
      "3 probability 3\n",
      "3 statistics 3\n",
      "3 Python 2\n",
      "3 pandas 2\n",
      "3 R 2\n",
      "3 statsmodels 2\n",
      "3 theory 1\n",
      "3 C++ 1\n",
      "3 artificial intelligence 1\n"
     ]
    }
   ],
   "source": [
    "lda_model.top_words_per_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_names = [\"Big Data and programming languages\",\n",
    "               \"Python and statistics\",\n",
    "               \"databases\",\n",
    "               \"machine learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Big Data and programming languages 7\n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "Python and statistics 5\n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "Python and statistics 2\n",
      "databases 2\n",
      "machine learning 2\n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "machine learning 3\n",
      "databases 2\n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "Python and statistics 2\n",
      "databases 2\n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "Big Data and programming languages 3\n",
      "databases 3\n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "machine learning 3\n",
      "databases 1\n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "Python and statistics 2\n",
      "databases 2\n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "Python and statistics 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "Big Data and programming languages 4\n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "machine learning 3\n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "machine learning 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "machine learning 3\n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "Python and statistics 5\n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "databases 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model.assign_topics(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({0: 7, 1: 0, 2: 0, 3: 0}),\n",
       " Counter({0: 0, 1: 5, 2: 0, 3: 0}),\n",
       " Counter({0: 0, 1: 2, 2: 2, 3: 2}),\n",
       " Counter({0: 0, 1: 0, 2: 2, 3: 3}),\n",
       " Counter({0: 0, 1: 2, 2: 2, 3: 0}),\n",
       " Counter({0: 3, 1: 0, 2: 3, 3: 0}),\n",
       " Counter({0: 0, 1: 0, 2: 1, 3: 3}),\n",
       " Counter({0: 0, 1: 2, 2: 2, 3: 0}),\n",
       " Counter({0: 1, 1: 3, 2: 0, 3: 0}),\n",
       " Counter({0: 4, 1: 0, 2: 0, 3: 0}),\n",
       " Counter({0: 0, 1: 0, 2: 0, 3: 3}),\n",
       " Counter({0: 1, 1: 0, 2: 0, 3: 3}),\n",
       " Counter({0: 0, 1: 0, 2: 0, 3: 3}),\n",
       " Counter({0: 0, 1: 5, 2: 0, 3: 0}),\n",
       " Counter({0: 0, 1: 0, 2: 3, 3: 0})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
