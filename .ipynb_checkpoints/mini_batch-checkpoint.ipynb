{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d87cb8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC4dJREFUeJzt3d+LXPUdxvHn6SZRq2FXqhVxxVioARG6GyRUFN0mRGKV\n5KYXCShUWtKLVgwtiPam8R8Qe1GEEDWCMaLRaJHWGjCLCK02iWuN2Vg0REz8sYqJUS8S1E8v5kS2\nIe2eDfv97sx+3i8YMrs7meezCc+cc2bOzNcRIQC5fGe2BwBQH8UHEqL4QEIUH0iI4gMJUXwgoa4o\nvu2Vtt+y/bbtuwtnPWR7wvbekjmT8i61vdP2Pttv2r6zcN7Ztl+1/XqTd2/JvCazz/Zrtp8rndXk\nHbT9hu0x27sKZw3Y3mZ7v+1x29cUzFrc/E4nL8dsry8SFhGzepHUJ+kdST+QtEDS65KuLJh3vaQl\nkvZW+v0ulrSkub5Q0r8L/36WdF5zfb6kVyT9uPDv+FtJj0l6rtK/6UFJF1TKekTSL5vrCyQNVMrt\nk/ShpMtK3H83bPGXSno7Ig5ExAlJj0taXSosIl6S9Gmp+z9N3gcRsae5/rmkcUmXFMyLiPii+XJ+\ncyl2lpbtQUk3S9pUKmO22O5XZ0PxoCRFxImIOFopfrmkdyLi3RJ33g3Fv0TSe5O+PqSCxZhNthdJ\nGlZnK1wyp8/2mKQJSTsiomTe/ZLukvRNwYxThaQXbO+2va5gzuWSPpb0cHMos8n2uQXzJlsjaWup\nO++G4qdg+zxJT0laHxHHSmZFxNcRMSRpUNJS21eVyLF9i6SJiNhd4v7/j+siYomkmyT92vb1hXLm\nqXNY+EBEDEv6UlLR56AkyfYCSaskPVkqoxuKf1jSpZO+Hmy+N2fYnq9O6bdExNO1cpvd0p2SVhaK\nuFbSKtsH1TlEW2b70UJZ34qIw82fE5K2q3O4WMIhSYcm7TFtU+eBoLSbJO2JiI9KBXRD8f8p6Ye2\nL28e6dZI+vMszzRjbFudY8TxiLivQt6Ftgea6+dIWiFpf4msiLgnIgYjYpE6/28vRsStJbJOsn2u\n7YUnr0u6UVKRV2gi4kNJ79le3HxruaR9JbJOsVYFd/Olzq7MrIqIr2z/RtLf1Hkm86GIeLNUnu2t\nkkYkXWD7kKQ/RMSDpfLU2SreJumN5rhbkn4fEX8plHexpEds96nzwP5ERFR5ma2SiyRt7zyeap6k\nxyLi+YJ5d0ja0myUDki6vWDWyQezFZJ+VTSneekAQCLdsKsPoDKKDyRE8YGEKD6QEMUHEuqq4hc+\n/XLWssgjr9vyuqr4kmr+41b9jySPvG7K67biA6igyAk8tjkraAZdccUV0/47n332mfr7+88ob968\n6Z/QeeTIEZ1//vlnlPf+++9P++8cP35cZ5111hnlHT1a6521syMiPNVtKH4PGB0drZo3MDBQNW/D\nhg1V85555pmqebW1KT67+kBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEmpV/JpLXAEob8riNx/a\n+Cd1PvL3SklrbV9ZejAA5bTZ4ldd4gpAeW2Kn2aJKyCLGftc/eaDA2q/ZxnAGWhT/FZLXEXERkkb\nJd6dB3S7Nrv6c3qJKyCjKbf4tZe4AlBeq2P8Zp23Umu9AaiMM/eAhCg+kBDFBxKi+EBCFB9IiOID\nCVF8ICGKDyQ0Y2/SQTm1l3y64YYbquaNjIxUzZvrK+m0wRYfSIjiAwlRfCAhig8kRPGBhCg+kBDF\nBxKi+EBCFB9IiOIDCbVZQush2xO299YYCEB5bbb4myWtLDwHgIqmLH5EvCTp0wqzAKiEY3wgIdbO\nAxKaseKzdh7QO9jVBxJq83LeVkl/l7TY9iHbvyg/FoCS2iyaubbGIADqYVcfSIjiAwlRfCAhig8k\nRPGBhCg+kBDFBxKi+EBCrJ13BoaGhqrm1V5brraxsbHZHiEdtvhAQhQfSIjiAwlRfCAhig8kRPGB\nhCg+kBDFBxKi+EBCFB9IqM2HbV5qe6ftfbbftH1njcEAlNPmXP2vJP0uIvbYXihpt+0dEbGv8GwA\nCmmzdt4HEbGnuf65pHFJl5QeDEA50zrGt71I0rCkV0oMA6CO1m/LtX2epKckrY+IY6f5OWvnAT2i\nVfFtz1en9Fsi4unT3Ya184De0eZZfUt6UNJ4RNxXfiQApbU5xr9W0m2Sltkeay4/LTwXgILarJ33\nsiRXmAVAJZy5ByRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoTmxdt769eur5m3YsKFqXn9/f9W8\n2kZHR2d7hHTY4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQhQfSIjiAwlRfCChNp+ye7btV22/3qyd\nd2+NwQCU0+Zc/eOSlkXEF83n679s+68R8Y/CswEopM2n7IakL5ov5zcXFswAelirY3zbfbbHJE1I\n2hERrJ0H9LBWxY+IryNiSNKgpKW2rzr1NrbX2d5le9dMDwlgZk3rWf2IOCppp6SVp/nZxoi4OiKu\nnqnhAJTR5ln9C20PNNfPkbRC0v7SgwEop82z+hdLesR2nzoPFE9ExHNlxwJQUptn9f8labjCLAAq\n4cw9ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJufOu2xm+U3tOv213YGCgat6RI0eq5tU2PFz3\n/LCxsbGqebVFhKe6DVt8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJNS6+M2iGq/Z\n5oM2gR43nS3+nZLGSw0CoJ62S2gNSrpZ0qay4wCooe0W/35Jd0n6puAsACpps5LOLZImImL3FLdj\n7TygR7TZ4l8raZXtg5Iel7TM9qOn3oi184DeMWXxI+KeiBiMiEWS1kh6MSJuLT4ZgGJ4HR9IqM2i\nmd+KiFFJo0UmAVANW3wgIYoPJETxgYQoPpAQxQcSovhAQhQfSIjiAwlN6wQeoIShoaGqeXN97bw2\n2OIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoVan7DYfrf25pK8lfcVHaAO9bTrn\n6v8kIj4pNgmAatjVBxJqW/yQ9ILt3bbXlRwIQHltd/Wvi4jDtr8vaYft/RHx0uQbNA8IPCgAPaDV\nFj8iDjd/TkjaLmnpaW7D2nlAj2izWu65theevC7pRkl7Sw8GoJw2u/oXSdpu++TtH4uI54tOBaCo\nKYsfEQck/ajCLAAq4eU8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQ\nxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhFoV3/aA7W2299set31N6cEAlNN2QY0/Sno+In5me4Gk\n7xacCUBhUxbfdr+k6yX9XJIi4oSkE2XHAlBSm139yyV9LOlh26/Z3tQsrPFfbK+zvcv2rhmfEsCM\nalP8eZKWSHogIoYlfSnp7lNvxBJaQO9oU/xDkg5FxCvN19vUeSAA0KOmLH5EfCjpPduLm28tl7Sv\n6FQAimr7rP4dkrY0z+gfkHR7uZEAlNaq+BExJoljd2CO4Mw9ICGKDyRE8YGEKD6QEMUHEqL4QEIU\nH0iI4gMJtT1zD5McPXq0at6zzz5bNW/16tVV80ZGRqrmbd68uWpeN2KLDyRE8YGEKD6QEMUHEqL4\nQEIUH0iI4gMJUXwgIYoPJDRl8W0vtj026XLM9voawwEoY8pTdiPiLUlDkmS7T9JhSdsLzwWgoOnu\n6i+X9E5EvFtiGAB1TLf4ayRtLTEIgHpaF7/5TP1Vkp78Hz9n7TygR0znbbk3SdoTER+d7ocRsVHS\nRkmyHTMwG4BCprOrv1bs5gNzQqviN8tir5D0dNlxANTQdgmtLyV9r/AsACrhzD0gIYoPJETxgYQo\nPpAQxQcSovhAQhQfSIjiAwlRfCAhR8z8+2lsfyzpTN6zf4GkT2Z4nG7IIo+8WnmXRcSFU92oSPHP\nlO1dEXH1XMsij7xuy2NXH0iI4gMJdVvxN87RLPLI66q8rjrGB1BHt23xAVRA8YGEKD6QEMUHEqL4\nQEL/AT9fgNySet2rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d87cb8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import random\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[1]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.33501649, -0.04308102,  0.27407152, -0.66447751,\n",
       "       -0.84412939, -0.40972392, -0.12502292, -0.05907756, -0.62400926,\n",
       "        0.4829745 ,  0.75962245, -0.05842586,  1.12772113,  0.87958306,\n",
       "       -0.13043338, -0.04462507,  0.11144272,  0.89588044, -0.86066632,\n",
       "       -1.14964846,  0.51547187,  1.90596347, -0.11422184, -0.03337973,\n",
       "        0.48648928,  0.46988512, -1.49990136, -1.61406277,  0.07639777,\n",
       "        1.54181413, -0.04723238,  0.        ,  0.76465553,  0.05263019,\n",
       "       -1.44763006, -1.73666443,  0.04361588,  1.43955804,  0.        ,\n",
       "       -0.06134367,  0.8105536 ,  0.63011714, -1.12245711, -1.06623158,\n",
       "        0.66096475,  0.81845076, -0.08874162, -0.03543326,  0.74211893,\n",
       "        1.15065212, -0.86867056,  0.11012973,  0.53761116, -0.75743581,\n",
       "       -0.20978513, -0.02359646, -0.29908135,  0.08671869,  0.20829258,\n",
       "       -0.36677122, -1.14664746, -0.5056698 , -0.19600752])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_structure = [64, 30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_deriv(x):\n",
    "    return f(x) * (1 - f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.random as r\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    h = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        # if it is the first layer, then the input into the weights is x, otherwise, \n",
    "        # it is the output from the last layer\n",
    "        if l == 1:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l] # z^(l+1) = W^(l)*h^(l) + b^(l)  \n",
    "        h[l+1] = f(z[l+1]) # h^(l) = f(z^(l)) \n",
    "    return h, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, h_out, z_out):\n",
    "    # delta^(nl) = -(y_i - h_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-h_out) * f_deriv(z_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mini_batches(X, y, batch_size):\n",
    "    random_idxs = random.choice(len(y), len(y), replace=False)\n",
    "    X_shuffled = X[random_idxs,:]\n",
    "    y_shuffled = y[random_idxs]\n",
    "    mini_batches = [(X_shuffled[i:i+batch_size,:], y_shuffled[i:i+batch_size]) for\n",
    "                   i in range(0, len(y), batch_size)]\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nn_MBGD(nn_structure, X, y, bs=100, iter_num=3000, alpha=0.25, lamb=0.000):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    m = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        mini_batches = get_mini_batches(X, y, bs)\n",
    "        for mb in mini_batches:\n",
    "            X_mb = mb[0]\n",
    "            y_mb = mb[1]\n",
    "            # pdb.set_trace()\n",
    "            for i in range(len(y_mb)):\n",
    "                delta = {}\n",
    "                # perform the feed forward pass and return the stored h and z values, \n",
    "                # to be used in the gradient descent step\n",
    "                h, z = feed_forward(X_mb[i, :], W, b)\n",
    "                # loop from nl-1 to 1 backpropagating the errors\n",
    "                for l in range(len(nn_structure), 0, -1):\n",
    "                    if l == len(nn_structure):\n",
    "                        delta[l] = calculate_out_layer_delta(y_mb[i,:], h[l], z[l])\n",
    "                        avg_cost += np.linalg.norm((y_mb[i,:]-h[l]))\n",
    "                    else:\n",
    "                        if l > 1:\n",
    "                            delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                        # triW^(l) = triW^(l) + delta^(l+1) * transpose(h^(l))\n",
    "                        tri_W[l] += np.dot(delta[l+1][:,np.newaxis], \n",
    "                                          np.transpose(h[l][:,np.newaxis])) \n",
    "                        # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                        tri_b[l] += delta[l+1]\n",
    "            # perform the gradient descent step for the weights in each layer\n",
    "            for l in range(len(nn_structure) - 1, 0, -1):\n",
    "                W[l] += -alpha * (1.0/bs * tri_W[l] + lamb * W[l])\n",
    "                b[l] += -alpha * (1.0/bs * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/m * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n",
      "Iteration 1000 of 3000\n",
      "Iteration 2000 of 3000\n"
     ]
    }
   ],
   "source": [
    "W, b, avg_cost_func = train_nn_MBGD(nn_structure, X_train, y_v_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_y(W, b, X, n_layers):\n",
    "    m = X.shape[0]\n",
    "    y = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        h, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(h[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.801112656467311"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
