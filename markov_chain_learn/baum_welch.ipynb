{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baum -Welch algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source http://www.adeveloperdiary.com/data-science/machine-learning/derivation-and-implementation-of-baum-welch-algorithm-for-hidden-markov-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    " \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            # Matrix Computation Steps\n",
    "            #                  ((1x2) . (1x2))      *     (1)\n",
    "            #                        (1)            *     (1)\n",
    "            alpha[t, j] = alpha[t - 1] @ a[:, j] * b[j, V[t]]\n",
    " \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]) @ a[j, :]\n",
    " \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    "\n",
    "    for n in range(n_iter):\n",
    "        ###estimation step\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    "\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            # joint probab of observed data up to time t @ transition prob * emisssion prob as t+1 @\n",
    "            # joint probab of observed data from time t+1\n",
    "            denominator = (alpha[t, :].T @ a * b[:, V[t + 1]].T) @ beta[t + 1, :]\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    "\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        ### maximization step\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    "\n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    "\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model A is \n",
      "[[0.53816345 0.46183655]\n",
      " [0.48664443 0.51335557]] \n",
      " \n",
      "Custom model B is \n",
      "[[0.16277513 0.26258073 0.57464414]\n",
      " [0.2514996  0.27780971 0.47069069]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_python.csv.txt')\n",
    "\n",
    "V = data['Visible'].values\n",
    "\n",
    "# Transition Probabilities\n",
    "a = np.ones((2, 2))\n",
    "a = a / np.sum(a, axis=1)\n",
    "\n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    "\n",
    "n_iter = 100\n",
    "a_model, b_model = baum_welch(V.copy(), a.copy(), b.copy(), initial_distribution.copy(), n_iter=n_iter)\n",
    "print(f'Custom model A is \\n{a_model} \\n \\nCustom model B is \\n{b_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmlearn A \n",
      "[[0.49678881 0.50321119]\n",
      " [0.49348432 0.50651568]]\n",
      "hmmlearn B \n",
      "[[0.15912386 0.2763461  0.56453004]\n",
      " [0.25179386 0.26380042 0.48440572]]\n"
     ]
    }
   ],
   "source": [
    "# compore to hmmlearn\n",
    "model = hmm.MultinomialHMM(n_components=2, n_iter=n_iter, init_params=\"\")\n",
    "model.startprob_ = initial_distribution\n",
    "model.transmat_ = a\n",
    "model.emissionprob_ = b\n",
    "\n",
    "model.fit([V])\n",
    "print(f'hmmlearn A \\n{model.transmat_}')\n",
    "print(f'hmmlearn B \\n{model.emissionprob_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A difference example implementation and hmmlearn \n",
      "[[ 0.04137464 -0.04137464]\n",
      " [-0.00683989  0.00683989]]\n",
      "B difference example implementation and hmmlearn \n",
      "[[ 0.00365127 -0.01376537  0.0101141 ]\n",
      " [-0.00029426  0.01400929 -0.01371503]]\n",
      "\n",
      "A example implementation and hmmlearn allclose: True\n",
      "B example implementation and hmmlearn allclose: True\n"
     ]
    }
   ],
   "source": [
    "print(f'A difference example implementation and hmmlearn \\n{a_model - (model.transmat_)}')\n",
    "print(f'B difference example implementation and hmmlearn \\n{b_model - (model.emissionprob_)}')\n",
    "print(f'\\nA example implementation and hmmlearn allclose: {np.allclose(a_model, model.transmat_, atol=0.1)}')\n",
    "print(f'B example implementation and hmmlearn allclose: {np.allclose(b_model, model.emissionprob_, atol=0.1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
