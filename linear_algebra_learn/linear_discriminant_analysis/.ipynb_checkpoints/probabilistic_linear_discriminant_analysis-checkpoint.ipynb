{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('mnist_demo/mnist_data/mnist_train_images.npy')\n",
    "training_labels = np.load('mnist_demo/mnist_data/mnist_train_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scatter_matrices(X, Y):\n",
    "    \"\"\" See Equations (1) on p.532 of Ioffe 2006. \"\"\"\n",
    "    assert len(X.shape) == 2\n",
    "    assert X.shape[0] == len(Y)\n",
    "\n",
    "    unique_labels = np.unique(Y)\n",
    "    labels = np.asarray(Y)\n",
    "\n",
    "    m = X.mean(axis=0)\n",
    "    N = X.shape[0]\n",
    "\n",
    "    cov_ks = []\n",
    "    m_ks = []\n",
    "    n_ks = []\n",
    "\n",
    "    for k in unique_labels:\n",
    "        bool_idxs = labels == k\n",
    "        X_k = X[bool_idxs]\n",
    "\n",
    "        m_ks.append(X_k.mean(axis=0))\n",
    "        n_ks.append(bool_idxs.sum())\n",
    "\n",
    "        cov_ks.append(np.cov(X_k.T))\n",
    "\n",
    "    n_ks = np.asarray(n_ks)\n",
    "    m_ks = np.asarray(m_ks)\n",
    "\n",
    "    m_ks_minus_m = m_ks - m\n",
    "    S_b = np.matmul(m_ks_minus_m.T * (n_ks / N), m_ks_minus_m)\n",
    "\n",
    "    S_w = np.asarray(cov_ks) * ((n_ks - 1) / N)[:, None, None]\n",
    "    S_w = np.sum(S_w, axis=0)\n",
    "\n",
    "    return S_b, S_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(X):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    assert len(X.shape) == 2\n",
    "    return X.mean(axis=0)\n",
    "\n",
    "def calc_W(S_b, S_w):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    eigenvalues, eigenvectors = eigh(S_b, S_w)\n",
    "    return eigenvectors\n",
    "\n",
    "def calc_Lambda_b(S_b, W):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    return np.matmul(np.matmul(W.T, S_b), W)\n",
    "\n",
    "def calc_Lambda_w(S_w, W):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    return np.matmul(np.matmul(W.T, S_w), W)\n",
    "\n",
    "def calc_n_avg(Y):\n",
    "    \"\"\" This is the \\\"hack\\\" suggested in Fig 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    unique = np.unique(Y)\n",
    "    return len(Y) / unique.shape[0]\n",
    "\n",
    "def calc_A(n_avg, Lambda_w, W):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    Lambda_w_diagonal = Lambda_w.diagonal()  # Should be diagonal matrix.\n",
    "    inv_W_T = np.linalg.inv(W.T)\n",
    "    return inv_W_T * (n_avg / (n_avg - 1) * Lambda_w_diagonal) ** .5\n",
    "\n",
    "\n",
    "def calc_Psi(Lambda_w, Lambda_b, n_avg):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    Lambda_w_diagonal = Lambda_w.diagonal()  # Should be diagonal matrix.\n",
    "    Lambda_b_diagonal = Lambda_b.diagonal()  # Should be diagonal matrix.\n",
    "    Psi = (n_avg - 1) / n_avg * Lambda_b_diagonal / Lambda_w_diagonal\n",
    "    Psi -= 1 / n_avg\n",
    "    Psi[Psi <= 0] = 0\n",
    "\n",
    "    return np.diag(Psi)\n",
    "\n",
    "def get_relevant_U_dims(Psi):\n",
    "    \"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\n",
    "    relevant_dims = np.squeeze(np.argwhere(Psi.diagonal() != 0))\n",
    "    if relevant_dims.shape == ():\n",
    "        relevant_dims = relevant_dims.reshape(1,)\n",
    "    return relevant_dims\n",
    "\n",
    "def optimize_maximum_likelihood(X, labels):\n",
    "    \"\"\" Performs the optimization in Fig. 2 of p.537 of Ioffe 2006.\n",
    "\n",
    "    DESCRIPTION\n",
    "     - The main model parameters are `m`, `A`, and `Psi`.\n",
    "     - However, to improve the performance (speed and numerical stability)\n",
    "        of the plda.Model object,\n",
    "        inv_A and relevant_U_dims are also returned here.\n",
    "\n",
    "    ADDITIONAL NOTES\n",
    "     Be sure to test that np.cov(X.T) is full rank before running this.\n",
    "\n",
    "     Recall that there are 4 \\\"spaces\\\":\n",
    "      'D' (data) <---> 'X' (preprocessed) <---> 'U' (latent) <---> 'U_model'\n",
    "\n",
    "    ARGUMENTS\n",
    "     X  (numpy.ndarray), shape=(n_data, n_dimensions)\n",
    "       - Data in statistics format, i.e. row-wise.\n",
    "\n",
    "     labels  (list or numpy.ndarray), length=X.shape[0]\n",
    "       - Labels for the data in `X`.\n",
    "       - Must be sorted in the same order as `X`.\n",
    "\n",
    "    RETURNS\n",
    "     m  (numpy.ndarray), shape=X.shape[-1]\n",
    "       - The mean of the row vectors in X.\n",
    "       - This is the prior mean fitted via maximum likelihood.\n",
    "\n",
    "     A  (numpy.ndarray), shape=(X.shape[-1], X.shape[-1])\n",
    "       - Transformation from X space to the latent U space.\n",
    "\n",
    "     Psi  (numpy.ndarray), shape=(X.shape[-1], X.shape[-1])\n",
    "       - The covariance matrix of the prior distribution on\n",
    "          the category means in U space.\n",
    "\n",
    "     relevant_U_dims  (numpy.ndarray), shape=(len(np.unique(labels)) - 1,)\n",
    "       - The \\\"effective\\\" latent dimensions,\n",
    "          i.e. the ones that are actually used by the model.\n",
    "\n",
    "     inv_A  (numpy.ndarray), shape=A.shape\n",
    "       - The inverse of the matrix A.\n",
    "       - Transformation from the latent U space to the X space.\n",
    "    \"\"\"\n",
    "    assert len(X.shape) == 2\n",
    "    assert X.shape[0] == len(labels)\n",
    "\n",
    "    m = X.mean(axis=0)\n",
    "\n",
    "    S_b, S_w = calc_scatter_matrices(X, labels)\n",
    "    W = calc_W(S_b, S_w)\n",
    "\n",
    "    Lambda_b = calc_Lambda_b(S_b, W)\n",
    "    Lambda_w = calc_Lambda_w(S_w, W)\n",
    "    n_avg = calc_n_avg(labels)\n",
    "\n",
    "    A = calc_A(n_avg, Lambda_w, W)\n",
    "    inv_A = np.linalg.inv(A)\n",
    "\n",
    "    Psi = calc_Psi(Lambda_w, Lambda_b, n_avg)\n",
    "    relevant_U_dims = get_relevant_U_dims(Psi)\n",
    "\n",
    "    return m, A, Psi, relevant_U_dims, inv_A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=training_data\n",
    "labels=training_labels\n",
    "n_principal_components=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatte matrices (not needed if n_principal components set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_b, S_w = calc_scatter_matrices(data, labels)\n",
    "matrix_rank = np.linalg.matrix_rank(S_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well set it to n_componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rank=n_principal_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=matrix_rank)\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = self.transform(data, from_space='D', to_space='X')\n",
    "\n",
    "X=pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learn params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, A, Psi, relevant_U_dims, inv_A = optimize_maximum_likelihood(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, data, labels, n_principal_components=None):\n",
    "    if n_principal_components is None:\n",
    "        S_b, S_w = calc_scatter_matrices(data, labels)\n",
    "        matrix_rank = np.linalg.matrix_rank(S_w)\n",
    "\n",
    "    else:\n",
    "        matrix_rank = n_principal_components\n",
    "\n",
    "    if matrix_rank != data.shape[-1]:\n",
    "        self.pca = PCA(n_components=matrix_rank)\n",
    "        self.pca.fit(data)\n",
    "\n",
    "    X = self.transform(data, from_space='D', to_space='X')\n",
    "\n",
    "    self.m, self.A, self.Psi, self.relevant_U_dims, self.inv_A = \\\n",
    "        optimize_maximum_likelihood(X, labels)\n",
    "\n",
    "    U_model = self.transform(X, from_space='X', to_space='U_model')\n",
    "\n",
    "    self.prior_params = \\\n",
    "        get_prior_params(self.Psi, self.relevant_U_dims)\n",
    "\n",
    "    self.posterior_params = \\\n",
    "        get_posterior_params(U_model, labels, self.prior_params)\n",
    "\n",
    "    self.posterior_predictive_params = \\\n",
    "        get_posterior_predictive_params(self.posterior_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
